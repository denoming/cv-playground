{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Face points detection\n",
    "\n",
    "* use shape_predictor_68_face_landmarks\n",
    "* use shape_predictor_5_face_landmarks\n",
    "\n",
    "# Links\n",
    "\n",
    "* [Dlib files](http://dlib.net/files/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b896ad4b9daf84a"
  },
  {
   "cell_type": "code",
   "source": [
    "import dlib\n",
    "import cv2\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from common import CV_DATASETS_DIR, show_full_image_plot, show_image_plot\n",
    "\n",
    "SHAPE_PREDICTOR_68 = \"shape_predictor_68_face_landmarks.dat\"\n",
    "SHAPE_PREDICTOR_05 = \"shape_predictor_5_face_landmarks.dat\"\n",
    "FACE_RESNET_MODEL = \"dlib_face_recognition_resnet_model_v1.dat\"\n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "points_detector_68 = dlib.shape_predictor(str(CV_DATASETS_DIR / \"models\" / SHAPE_PREDICTOR_68))\n",
    "face_descriptor_extractor = dlib.face_recognition_model_v1(str(CV_DATASETS_DIR / \"models\" / FACE_RESNET_MODEL))\n",
    "\n",
    "def get_image_data(path: Path) -> (List[np.array], List[Path]):\n",
    "    images = []\n",
    "    labels = []\n",
    "    files = path.glob('*.gif')\n",
    "    for file in files:\n",
    "        images.append(np.array(Image.open(file).convert(\"RGB\"), \"uint8\"))\n",
    "        labels.append(file)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def get_images_descriptors(images: List[np.array], labels: List[Path]) -> Tuple[Dict[int, Path], any]:\n",
    "    idx = 0\n",
    "    index = {}\n",
    "    descriptors = None\n",
    "    for image, label in zip(images, labels):\n",
    "        for face in face_detector(image, 1):\n",
    "            points = points_detector_68(image, face)\n",
    "            assert len(points.parts()) > 0\n",
    "            descriptor = face_descriptor_extractor.compute_face_descriptor(image, points)\n",
    "            descriptor = [_ for _ in descriptor]\n",
    "            descriptor = np.asarray(descriptor, dtype=np.float64)\n",
    "            descriptor = descriptor[np.newaxis, :]\n",
    "            if descriptors is None:\n",
    "                descriptors = descriptor\n",
    "            else:\n",
    "                descriptors = np.concatenate((descriptors, descriptor), axis=0)\n",
    "            index[idx] = label\n",
    "            idx += 1  \n",
    "    return index, descriptors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f79a9ee1cd7f8dae",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1eb2b5bc636b4bbf"
  },
  {
   "cell_type": "code",
   "source": [
    "train_images, train_labels = get_image_data(CV_DATASETS_DIR / 'images' / 'yalefaces' / 'train')\n",
    "train_index, train_descriptors = get_images_descriptors(train_images, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aa9bdb96b5e7699",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc2881e3bb62201"
  },
  {
   "cell_type": "code",
   "source": [
    "test_images, test_labels = get_image_data(CV_DATASETS_DIR / 'images' / 'yalefaces' / 'test')\n",
    "test_index, test_descriptors = get_images_descriptors(test_images, test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T15:16:34.782687Z",
     "start_time": "2024-04-01T15:16:29.947878Z"
    }
   },
   "id": "e283a542feb5e8d",
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import seaborn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "MIN_THRESHOLD = 0.5\n",
    "\n",
    "preds = []\n",
    "reals = []\n",
    "\n",
    "for index, image, descriptor in zip(test_index, test_images, test_descriptors):\n",
    "    distances = np.linalg.norm(descriptor - train_descriptors, axis=1)\n",
    "    min_i = np.argmin(distances)\n",
    "    min_d = distances[min_i]\n",
    "    if min_d <= MIN_THRESHOLD:\n",
    "        pred = int(train_index[min_i].stem.split(\".\")[0].replace(\"subject\", \"\"))\n",
    "    else:\n",
    "        pred = -1\n",
    "    real = int(test_index[index].stem.split(\".\")[0].replace(\"subject\", \"\"))\n",
    "    preds.append(pred)\n",
    "    reals.append(real)\n",
    "    \n",
    "preds = np.array(preds)\n",
    "reals = np.array(reals)\n",
    "\n",
    "accuracy = accuracy_score(reals, preds)\n",
    "print(f'Accuracy: {accuracy * 100:.3f}%')\n",
    "cm = confusion_matrix(reals, preds)\n",
    "seaborn.heatmap(cm, annot=True);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T15:28:35.789343Z",
     "start_time": "2024-04-01T15:28:35.519714Z"
    }
   },
   "id": "bbee8f0a51855ac5",
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "acb67be80e7f0e24",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
