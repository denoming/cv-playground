{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T19:08:55.910939Z",
     "start_time": "2025-08-21T19:08:54.627151Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import keras\n",
    "from pathlib import Path\n",
    "\n",
    "# Placement logs is disabled (default)\n",
    "tf.debugging.set_log_device_placement(False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 22:08:54.911101: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-21 22:08:54.938005: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-21 22:08:55.493183: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:08:58.064596Z",
     "start_time": "2025-08-21T19:08:57.983938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for device in tf.config.list_physical_devices(\"GPU\"):\n",
    "    print(f\"Device: {device.name}, Type: {device.device_type}\")"
   ],
   "id": "4e27955f12e75fc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: /physical_device:GPU:0, Type: GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Basic",
   "id": "f161538ec51cde9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rank-0 tensor\n",
    "x0 = tf.constant(4, dtype=tf.float16)\n",
    "print(f\"x0: {x0}\")\n",
    "\n",
    "# rank-1 tensor\n",
    "x1 = tf.constant(\n",
    "    [1.0, 2.0, 3.0],\n",
    "    dtype=tf.float16)\n",
    "print(f\"x1: {x1}\")\n",
    "\n",
    "# rank-2 tensor\n",
    "x2 = tf.constant([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]], dtype=tf.float16)\n",
    "print(f\"x2: {x2}\")\n",
    "\n",
    "print(f\"Convert to numpy array: {type(x2.numpy())}\")"
   ],
   "id": "a9f61c0e582d9de4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert some object to tensor\n",
    "y = tf.convert_to_tensor([1,2,3])\n",
    "print(f\"Value: {y}\")"
   ],
   "id": "579c85cc024a11b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.ones([2, 2], dtype=tf.int32)\n",
    "\n",
    "print(f\"Add: {tf.add(a, b)}\") # or a + b\n",
    "print(f\"Mul: {tf.multiply(a, b)}\") # or a * b\n",
    "print(f\"Matrix mul: {tf.matmul(a, b)}\") # or a @ b"
   ],
   "id": "12214aeb8cba5365",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "c = tf.constant([[4.0, 5.0],\n",
    "                 [10.0, 1.0]])\n",
    "print(f\"Largest value: {tf.reduce_max(c)}\")\n",
    "print(f\"The index of largest value: {tf.math.argmax(c)}\")\n",
    "print(f\"Softmax: {tf.nn.softmax(c)}\")"
   ],
   "id": "17d1a6c9cae3c3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reshape\n",
    "x = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], dtype=tf.float16)\n",
    "print(f\"Shape: {x.shape}\")\n",
    "y = tf.reshape(x, [3, 2])\n",
    "print(f\"ReShape: {y}\")\n"
   ],
   "id": "9c0a200272924172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define mutable tensor (represents shared, persistent state to manipulate of)\n",
    "# Usage: storing model parameters (e.g. weights)\n",
    "z = tf.Variable([0.0, 0.0, 0.0])\n",
    "print(f\"Value: {z}\")\n",
    "z.assign([1.0, 2.0, 3.0])\n",
    "print(f\"Value: {z}\")"
   ],
   "id": "15087f460409b3db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define not rectangular tensor\n",
    "z = tf.ragged.constant([\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]\n",
    "])\n",
    "print(f\"Not-rectangular tensor: {z}\")\n",
    "print(f\"Not-rectangular tensor (shape): {z.shape}\")"
   ],
   "id": "2307a2a6b9f5cd31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "287662edc2488701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define sparce tensor\n",
    "s = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                           values=[1, 2],\n",
    "                           dense_shape=[3, 4])\n",
    "print(f\"Sparse: {s}\")\n",
    "print(f\"Sparce to dence: {tf.sparse.to_dense(s)}\")"
   ],
   "id": "4f1f13da513a9645",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Logging of device location must be set from session start\n",
    "with tf.device(\"CPU:0\"):\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "  c = tf.matmul(a, b)\n",
    "print(f\"Result: {c}\")"
   ],
   "id": "6472f6a7ea24aaec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Automatic differentiation",
   "id": "1f732e3a5684674d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T19:09:04.517363Z",
     "start_time": "2025-08-21T19:09:04.514328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# AD with respect to scalar\n",
    "#\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "\n",
    "dx = tape.gradient(y, x)\n",
    "print(f\"Result: {dx.numpy()}\")"
   ],
   "id": "db1247a6c4233d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 6.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:55:30.186995Z",
     "start_time": "2025-08-21T18:55:30.107041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# AD with respect to tensor\n",
    "#\n",
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = x @ w + b\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "grad = tape.gradient(loss, {\n",
    "    \"w\": w,\n",
    "    \"b\": b,\n",
    "})\n",
    "print(f\"w.shape = {w.shape}\")\n",
    "print(f\"dw.shape = {grad[\"w\"].shape}\")"
   ],
   "id": "9cb9835dbd89bcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.shape = (3, 2)\n",
      "dw.shape = (3, 2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# AD with respect to a model\n",
    "#\n",
    "\n",
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Forward propagation\n",
    "    y = layer(x)\n",
    "    loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Back propagation\n",
    "grad = tape.gradient(loss, layer.trainable_variables)\n",
    "\n",
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "    print(f\"{var.name}, shape: {g.shape}\")"
   ],
   "id": "2f6cb75cd66da70e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# AD with selecting what to watch to calculate gradients against\n",
    "#\n",
    "\n",
    "x0 = tf.Variable(0.0)\n",
    "x1 = tf.Variable(10.0)\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "  tape.watch(x1)\n",
    "  y0 = tf.math.sin(x0)\n",
    "  y1 = tf.nn.softplus(x1)\n",
    "  y = y0 + y1\n",
    "  ys = tf.reduce_sum(y)\n",
    "\n",
    "# dys/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\n",
    "grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n",
    "\n",
    "print('dy/dx0:', grad['x0'])\n",
    "print('dy/dx1:', grad['x1'].numpy())"
   ],
   "id": "723997a4e11d3563",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save and restore model (all variables declared inside)\n",
    "class ExampleModel(tf.Module):\n",
    "    def __init__(self, value):\n",
    "        super().__init__()\n",
    "        self.weights = tf.Variable(value)\n",
    "\n",
    "    @tf.function\n",
    "    def mul(self, x):\n",
    "        return x * self.weights\n",
    "\n",
    "module = ExampleModel(3)\n",
    "tf.print(module.mul(tf.constant([1, 2, 3])))\n",
    "\n",
    "save_path = tempfile.gettempdir()\n",
    "tf.saved_model.save(module, save_path)\n",
    "\n",
    "reloaded = tf.saved_model.load(save_path)\n",
    "tf.print(reloaded.mul(tf.constant([1, 1, 1])))"
   ],
   "id": "80fa8721d588aaa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graph",
   "id": "1a54f1654c97337d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def inner_fn(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "# Decorator makes function into a `PolymorphicFunction`\n",
    "# as well applying this transformation to other functions it calls\n",
    "@tf.function\n",
    "def outer_fn(x):\n",
    "    y = tf.constant([[2.0], [3.0]])\n",
    "    b = tf.constant(4.0)\n",
    "\n",
    "    return inner_fn(x, y, b)\n",
    "\n",
    "\n",
    "print(f\"Type: {type(outer_fn)}\")\n",
    "\n",
    "\n",
    "result = outer_fn(tf.constant([[1.0, 2.0]]))\n",
    "print(f\"Result: {result}\")"
   ],
   "id": "85c6063b83d97560",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def simple_relu(x):\n",
    "    if tf.greater(x, 0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\">>> Graph-generated output of AutoGraph:\")\n",
    "print(tf.autograph.to_code(simple_relu))\n",
    "\n",
    "print(\">>> Graph:\")\n",
    "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
   ],
   "id": "f726b53e0cb4764",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Turnt off running graphs and force to run as ordinary function\n",
    "tf.config.run_functions_eagerly(True)\n",
    "simple_relu(tf.constant(-1.0))\n",
    "tf.config.run_functions_eagerly(False)"
   ],
   "id": "f6a65568d17a56db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tracing captures the TensorFlow operations and discard all other\n",
    "# We observe only one print statement when tf.function runs the original code\n",
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "  print(\"Calculating MSE!\")\n",
    "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "  return tf.reduce_mean(sq_diff)\n",
    "\n",
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ],
   "id": "e1825a00050b5ab9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "\n",
    "# Ordinary functions\n",
    "def power(x, y):\n",
    "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "  for _ in range(y):\n",
    "    result = tf.matmul(x, result)\n",
    "  return result\n",
    "\n",
    "# Grapth function\n",
    "power_as_graph = tf.function(power)\n",
    "\n",
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000), \"seconds\")\n",
    "\n",
    "power_as_graph = tf.function(power)\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000), \"seconds\")"
   ],
   "id": "72a3a734593ed77e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Module",
   "id": "da99769c7cb137eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using module",
   "id": "abaf77c1d46bfc90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MyModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.var1 = tf.Variable(5.0, name=\"train_me\")\n",
    "        self.var2 = tf.Variable(5.0, trainable=False, name=\"do_not_train_me\")\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        return self.var1 * x + self.var2"
   ],
   "id": "e3b44e4496e099e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model1 = MyModule(name=\"simple\")\n",
    "\n",
    "model1(tf.constant(5.0))"
   ],
   "id": "e6653619fc818567",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# All trainable variables\n",
    "print(\"Trainable variables:\", model1.trainable_variables)\n",
    "# Every variable\n",
    "print(\"All variables:\", model1.variables)"
   ],
   "id": "8a4288ccedeb4ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Dense(tf.Module):\n",
    "    def __init__(self, in_features, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        tf.random.set_seed(0)\n",
    "        self.w = tf.Variable(tf.random.normal([in_features, out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)\n",
    "\n",
    "class SequentialModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "        self.dense_2 = Dense(in_features=3, out_features=2)\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        return self.dense_2(x)"
   ],
   "id": "a4f66494044bcee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# You have made a model!\n",
    "model2 = SequentialModule(name=\"model2\")\n",
    "print(\"Model results (model2):\", model2(tf.constant([[2.0, 2.0, 2.0]])))"
   ],
   "id": "5c3547ac38ab6f84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Every module\n",
    "print(\"All submodules:\", model2.submodules)\n",
    "# Every variable\n",
    "print(\"All variables:\", model2.variables)"
   ],
   "id": "7bc1d3971bdb11a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving checkpoint",
   "id": "7ed2e4d10dfd2c0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "export_path = Path(tempfile.gettempdir()) / \"checkpoint\"\n",
    "checkpoint1 = tf.train.Checkpoint(model=model2)\n",
    "checkpoint1.write(export_path)"
   ],
   "id": "9c870709bd07bcaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tf.train.list_variables(export_path)",
   "id": "e33fd5327684fb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3 = SequentialModule(name=\"model3\")\n",
    "checkpoint2 = tf.train.Checkpoint(model=model3)\n",
    "checkpoint2.restore(export_path)\n",
    "\n",
    "model3(tf.constant([[2.0, 2.0, 2.0]]))\n",
    "print(\"Model results (model3):\", model3(tf.constant([[2.0, 2.0, 2.0]])))"
   ],
   "id": "8c4e27d9f5c50220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving model",
   "id": "b914736772ea3df2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Saved model contains both a collection of functions and a collection of weights\n",
    "export_path = Path(tempfile.gettempdir()) / \"saved_model\"\n",
    "tf.saved_model.save(model2, export_path)"
   ],
   "id": "2e654cff9c216265",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%ls -l {export_path}",
   "id": "cf21f773f0ecd9b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The variable directory contains a checkpoint of the variables\n",
    "%ls -l {export_path / \"variables\"}"
   ],
   "id": "862be5e3f0fc1642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model4 = tf.saved_model.load(export_path)\n",
    "\n",
    "# loaded model is an internal TF user object without any of class knowledge\n",
    "print(\"Is instance of SequentialModule:\", isinstance(model4, SequentialModule))"
   ],
   "id": "96b1ad61acf7fb87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(model4(tf.constant([[2.0, 2.0, 2.0]])))",
   "id": "216f3380a3e5eb4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create layer using subclassing from Keras",
   "id": "69c04559ecfc3917"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class FlexibleDense(tf.keras.layers.Layer):\n",
    "    # Note the added `**kwargs`, as Keras supports many arguments\n",
    "    def __init__(self, out_features, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_features = out_features\n",
    "\n",
    "    # Create the state of the layer (weights)\n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.out_features]), name='w')\n",
    "        self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "\n",
    "    # Defines the computation from inputs to outputs\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class FlexibleSequentialModel(tf.keras.Model):\n",
    "  def __init__(self, name=None, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.dense_1 = FlexibleDense(out_features=3)\n",
    "    self.dense_2 = FlexibleDense(out_features=2)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)"
   ],
   "id": "324fab08716da070",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the instance of the layer\n",
    "model5 = FlexibleSequentialModel(name=\"model5\")\n",
    "print(\"Model results:\", model5(tf.constant([[2.0, 2.0, 2.0]])))"
   ],
   "id": "543a9850c98ca31c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving Keras model",
   "id": "a708b0dd4f83c9e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "export_path = Path(tempfile.gettempdir()) / \"model5.keras\"\n",
    "model5.save(export_path)"
   ],
   "id": "c1d669f7c3634a31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model6 = keras.models.load_model(export_path)\n",
    "print(\"Reconstructed model results:\", model6(tf.constant([[2.0, 2.0, 2.0]])))"
   ],
   "id": "69b6ba376e923e72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training loop",
   "id": "30de7f381a497cf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRUE_W = 3.0\n",
    "TRUE_B = 2.0\n",
    "NUM_EXAMPLES = 201\n",
    "\n",
    "# A vector of random x values\n",
    "x = tf.linspace(-2,2, NUM_EXAMPLES)\n",
    "x = tf.cast(x, tf.float32)\n",
    "\n",
    "def f(x):\n",
    "  return x * TRUE_W + TRUE_B\n",
    "\n",
    "# Generate some noise\n",
    "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "# Calculate y\n",
    "y = f(x) + noise"
   ],
   "id": "c1aa983015dff13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot all the data\n",
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "plt.plot(x, f(x), label=\"Ground truth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "694591c40aea3ee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training without Keras",
   "id": "fe93a2b642891f08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CustomModel(tf.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w * x + self.b"
   ],
   "id": "845ba2e94bf3e373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "model7 = CustomModel()\n",
    "\n",
    "# List\n",
    "print(\"Variables: {}\".format(model7.variables))\n",
    "\n",
    "# Verify the model works\n",
    "assert model7(3.0).numpy() == 15.0"
   ],
   "id": "a0386ab640965e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define loss function\n",
    "def loss(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))\n",
    "\n",
    "# Define train function\n",
    "def train(model, x, y, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        # Trainable variables are automatically tracked by GradientTape\n",
    "        current_loss = loss(y, model(x))\n",
    "\n",
    "    # Use GradientTape.gradient to calculate the gradients with respect to w and b\n",
    "    dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "\n",
    "    # Subtract the gradient scaled by the learning rate\n",
    "    model.w.assign_sub(learning_rate * dw)\n",
    "    model.b.assign_sub(learning_rate * db)"
   ],
   "id": "3f7e8eb707a14034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Collect the history of W-values and b-values to plot later\n",
    "weights = []\n",
    "biases = []\n",
    "epochs = range(10)\n",
    "\n",
    "# Define a training loop\n",
    "def report(model, loss):\n",
    "  return f\"W = {model.w.numpy():1.2f}, b = {model.b.numpy():1.2f}, loss={loss:2.5f}\"\n",
    "\n",
    "def training_loop(model, x, y):\n",
    "  for epoch in epochs:\n",
    "    # Update the model with the single giant batch\n",
    "    train(model, x, y, learning_rate=0.1)\n",
    "\n",
    "    # Track this before I update\n",
    "    weights.append(model.w.numpy())\n",
    "    biases.append(model.b.numpy())\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "    print(f\"Epoch {epoch:2d}:\")\n",
    "    print(\"    \", report(model, current_loss))"
   ],
   "id": "641b6b77585223d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "plt.plot(x, f(x), label=\"Ground truth\")\n",
    "plt.plot(x, model7(x), label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Current loss: %1.6f\" % loss(y, model7(x)).numpy())"
   ],
   "id": "4d2af1f9bce49447",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "current_loss = loss(y, model7(x))\n",
    "\n",
    "print(f\"Starting:\")\n",
    "print(\"    \", report(model7, current_loss))\n",
    "\n",
    "training_loop(model7, x, y)"
   ],
   "id": "17936ad20f023039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "plt.plot(epochs, weights, label='Weights', color=colors[0])\n",
    "plt.plot(epochs, [TRUE_W] * len(epochs), '--',\n",
    "         label = \"True weight\", color=colors[0])\n",
    "\n",
    "plt.plot(epochs, biases, label='bias', color=colors[1])\n",
    "plt.plot(epochs, [TRUE_B] * len(epochs), \"--\",\n",
    "         label=\"True bias\", color=colors[1])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "f177df2f8c32c843",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "plt.plot(x, f(x), label=\"Ground truth\")\n",
    "plt.plot(x, model7(x), label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Current loss: %1.6f\" % loss(model7(x), y).numpy())"
   ],
   "id": "b75ae0458c73b628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training with Keras",
   "id": "d099b8efcfdbcf85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CustomKerasModel(keras.Model):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.w * x + self.b"
   ],
   "id": "2d59549b61eca6a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model8 = CustomKerasModel()\n",
    "\n",
    "# compile sets the training parameters\n",
    "model8.compile(\n",
    "    # By default, fit() uses tf.function().  You can\n",
    "    # turn that off for debugging, but it is on now.\n",
    "    run_eagerly=False,\n",
    "\n",
    "    # Using a built-in optimizer, configuring as an object\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1),\n",
    "\n",
    "    # Keras comes with built-in MSE error\n",
    "    # However, you could use the loss function\n",
    "    # defined above\n",
    "    loss=keras.losses.mean_squared_error,\n",
    ")"
   ],
   "id": "d1b6dbe3105f7315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(x.shape[0])\n",
    "model8.fit(x, y, epochs=10, batch_size=1000)"
   ],
   "id": "c3ff2ebc34216afe",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
