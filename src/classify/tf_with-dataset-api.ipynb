{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TensorFlow: DNN using TF dataset API\n",
    "\n",
    "Demonstrates creating DNN to accomplish image classification with Conv2D and MaxPool2D layers.\n",
    "Model is trained on horses-and-humans dataset."
   ],
   "id": "aee581d84ff65838"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-04T13:58:27.873419Z",
     "start_time": "2025-09-04T13:58:27.871696Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "from common import CV_DATA_DIR\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare dataset",
   "id": "bef3222ffa9638c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load datase\n",
    "(train_ds, test_ds), ds_info = tfds.load('horses_or_humans',\n",
    "                                         split=['train', 'test'],\n",
    "                                         batch_size=32,\n",
    "                                         with_info=True,\n",
    "                                         as_supervised=True)\n"
   ],
   "id": "e693946fb3f53f38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'Number of training examples: {ds_info.splits['train'].num_examples}')\n",
    "print(f'Number of testing examples: {ds_info.splits['test'].num_examples}')\n",
    "print(f'Number of classes: {ds_info.features['label'].num_classes}')\n",
    "print(f'Image shape: {ds_info.features['image'].shape}')"
   ],
   "id": "25cf3ac608622517",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "VAL_DIR = CV_DATA_DIR / 'animals' / 'horses-and-humans' / 'val'\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "# Rescale train dataset\n",
    "train_ds = (train_ds\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# Rescale test dataset\n",
    "test_ds = (test_ds\n",
    "   .cache()\n",
    "   .prefetch(BUFFER_SIZE))\n",
    "\n",
    "valid_ds = None\n",
    "if VAL_DIR.is_dir():\n",
    "    valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        VAL_DIR,\n",
    "        image_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        label_mode='binary')\n",
    "    valid_ds = (valid_ds\n",
    "        .cache()\n",
    "        .prefetch(BUFFER_SIZE))"
   ],
   "id": "6c8b63d29fd49571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Take one batch from dataset\n",
    "sample_batch = list(train_ds.take(1))[0]\n",
    "\n",
    "image_batch = sample_batch[0]\n",
    "label_batch = sample_batch[1]\n",
    "\n",
    "# Extract images and labels from batch\n",
    "print(f'Image batch shape: {image_batch.shape}')\n",
    "print(f'Label batch shape: {label_batch.shape}')\n",
    "print(f'Max value: {np.max(image_batch[0].numpy())}')\n",
    "print(f'Min value: {np.min(image_batch[0].numpy())}')"
   ],
   "id": "77c1b661945bd124",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define model",
   "id": "b6d97698f52c8c4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Input with 300x300x3 shape\n",
    "    tf.keras.Input(shape=(300, 300, 3)),\n",
    "    # Rescale input volume\n",
    "    tf.keras.layers.Rescaling(scale=1./255),\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Binary classification: 0 - 'horses', 1 - 'humans'\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "id": "a148c5865c769dff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Output model summary\n",
    "model.summary()"
   ],
   "id": "fd9e6ad1173857ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ],
   "id": "eccea160e418f1b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train model",
   "id": "6b0dc345f0ff6f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class StopCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Print available metric\n",
    "        keys = list(logs.keys())\n",
    "        print('End epoch {} of training; got log keys: {}'.format(epoch, keys))\n",
    "        # Check if we reached desired accuracy value\n",
    "        if logs.get('accuracy') >= 0.99:\n",
    "            print('\\nReached 90% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Train on train set\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[StopCallback()],\n",
    "    verbose=2,\n",
    "    validation_data=valid_ds)"
   ],
   "id": "bd6d60c31439dced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "if valid_ds is not None:\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ],
   "id": "8c5158d5f0fe6170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate on test set\n",
    "model.evaluate(test_ds, verbose=2)"
   ],
   "id": "993937e66f909740",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
