{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T19:34:22.026911Z",
     "start_time": "2024-10-28T19:34:21.065234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Set various TF options\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.api as keras\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"TF device:\", tf.config.list_physical_devices('GPU')) # or 'CPU'"
   ],
   "id": "8850637a5184e29d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.17.1\n",
      "TF device: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Approach 1",
   "id": "9b5b11e6759adb1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extracting pixels from images",
   "id": "1e74b9aa8cb51b51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T12:26:42.837197Z",
     "start_time": "2024-10-27T12:26:42.621488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from common import CV_DATA_DIR\n",
    "from pathlib import Path\n",
    "\n",
    "# Pre-processed input images\n",
    "images = []\n",
    "# Classes of input images\n",
    "classes = []\n",
    "# Shape of input image (height x width = NN inputs)\n",
    "height, width = 64, 64\n",
    "\n",
    "# Filter out regular files\n",
    "files = [\n",
    "    file for file in sorted(Path(CV_DATA_DIR, 'homer_bart_1').iterdir())\n",
    "    if file.is_file()\n",
    "]\n",
    "\n",
    "# Pre-process images\n",
    "for file in files:\n",
    "    try:\n",
    "        image = cv.imread(str(file))\n",
    "\n",
    "        # Reshape images to have exact size (each pixel will be as an input of NN)\n",
    "        image = cv.resize(image, (width, height))\n",
    "        # Convert to grayscale (reduce amount of neurons in input layer of NN, 49152 vs 16384) \n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        # Convert matrix to a vector\n",
    "        image = image.ravel()\n",
    "\n",
    "        images.append(image)\n",
    "        classes.append(0 if file.name.startswith('b') else 1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Form images and classes arrays \n",
    "Xs = np.asarray(images)\n",
    "Ys = np.asarray(classes)\n",
    "\n",
    "(classes, counts) = np.unique(Ys, return_counts=True)\n",
    "print(f'Bart class images ({classes[0]}): {counts[0]}')\n",
    "print(f'Homer class images ({classes[1]}): {counts[1]}')"
   ],
   "id": "289ffc1549cd0e59",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/denys/projects/cv-playground/datasets/homer_bart_1'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 13\u001B[0m\n\u001B[1;32m      9\u001B[0m height, width \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m64\u001B[39m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Filter out regular files\u001B[39;00m\n\u001B[1;32m     12\u001B[0m files \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m---> 13\u001B[0m     file \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCV_DATASETS_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhomer_bart_1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file\u001B[38;5;241m.\u001B[39mis_file()\n\u001B[1;32m     15\u001B[0m ]\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Pre-process images\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m files:\n",
      "File \u001B[0;32m/usr/lib/python3.12/pathlib.py:1056\u001B[0m, in \u001B[0;36mPath.iterdir\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1050\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21miterdir\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1051\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Yield path objects of the directory contents.\u001B[39;00m\n\u001B[1;32m   1052\u001B[0m \n\u001B[1;32m   1053\u001B[0m \u001B[38;5;124;03m    The children are yielded in arbitrary order, and the\u001B[39;00m\n\u001B[1;32m   1054\u001B[0m \u001B[38;5;124;03m    special entries '.' and '..' are not included.\u001B[39;00m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1057\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_child_relpath(name)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/denys/projects/cv-playground/datasets/homer_bart_1'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalizing data",
   "id": "78028df248987dee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize pixel values for better result ([0, 255] => [0, 1])\n",
    "scaler = MinMaxScaler()\n",
    "Xs = scaler.fit_transform(Xs)"
   ],
   "id": "322cd72b0a30ed6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train and test set",
   "id": "30f1ff1d4458c02c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split a bunch of input images to train and test image groups\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(Xs, Ys, test_size=0.2, random_state=1)"
   ],
   "id": "d3a3ebe57ae18454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building and training NN",
   "id": "343d41d9c220fcfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inputs = width * height\n",
    "output_classes = 2\n",
    "hidden_neurons = int((inputs + output_classes) / 2)\n",
    "\n",
    "# Create neural network (NN)\n",
    "model0 = keras.Sequential()\n",
    "model0.add(keras.Input(shape=(inputs,)))\n",
    "model0.add(keras.layers.Dense(units=hidden_neurons, activation='relu'))\n",
    "model0.add(keras.layers.Dense(units=hidden_neurons, activation='relu'))\n",
    "model0.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model0.summary()"
   ],
   "id": "af920b3a07ceb45f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile NN and fit\n",
    "model0.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model0.fit(Xs_train, Ys_train, epochs=50, verbose=1)"
   ],
   "id": "a522b7b6b0a2d054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating NN",
   "id": "e886d3742eac00dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = model0.predict(Xs_test)\n",
    "predictions = (predictions > 0.5)  # (0 - Bart, 1 - Homer)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(Ys_test, predictions)))"
   ],
   "id": "bd0a8dde7a406af6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Ys_test, predictions)\n",
    "sns.heatmap(cm, annot=True);"
   ],
   "id": "408bb429ebadc687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Ys_test, predictions))"
   ],
   "id": "4f275da1a713f128",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving and loading NN",
   "id": "c2b0018938da0a17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from common import CV_WORKAREA_DIR\n",
    "\n",
    "MODEL_FILE = Path(CV_WORKAREA_DIR, 'home_bart1.json')\n",
    "MODEL_WEIGHTS_FILE = Path(CV_WORKAREA_DIR, 'home_bart1.keras')\n",
    "\n",
    "model_json = model0.to_json()\n",
    "with open(MODEL_FILE, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "keras.models.save_model(model0, MODEL_WEIGHTS_FILE)"
   ],
   "id": "efb4c428ec4358f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(MODEL_FILE) as json_file:\n",
    "    json_model = json_file.read()\n",
    "\n",
    "model1 = keras.models.model_from_json(json_model)\n",
    "model1.load_weights(MODEL_WEIGHTS_FILE)\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ],
   "id": "466f67cb33b2c140",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classifying one single image",
   "id": "59bc28ee56c32f47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_image = Xs_test[34]\n",
    "test_image = scaler.inverse_transform(test_image.reshape(1, -1))"
   ],
   "id": "942836924261a659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from common import show_image_plot\n",
    "\n",
    "show_image_plot(test_image.reshape(width, height))"
   ],
   "id": "e5ab165caebb019b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prediction = model1.predict(test_image)[0][0]\n",
    "if prediction < 0.5:\n",
    "    print(\"Bart\")\n",
    "else:\n",
    "    print(\"Homer\")"
   ],
   "id": "5df62eddc415781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Approach 2 (feature extraction)\n",
    "\n",
    "Will be used feature extraction technique based on color.\n",
    "\n",
    "Homer features:\n",
    " * Brown (mouth)\n",
    " * Blue (pants)\n",
    " * Gray (shoes)\n",
    "\n",
    "Bart features:\n",
    " * Orange (T-shirt)\n",
    " * Blue (shorts)\n",
    " * Blue (sneakers)\n",
    "     "
   ],
   "id": "7f4c8be6fde2b329"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from common import CV_DATA_DIR\n",
    "from pathlib import Path\n",
    "\n",
    "# Filter out regular files\n",
    "files = [\n",
    "    file for file in sorted(Path(CV_DATA_DIR, 'homer_bart_1').iterdir())\n",
    "    if file.is_file()\n",
    "]"
   ],
   "id": "3287075ec62ed318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "export = 'mount,pants,shoes,tshirt,shorts,sneakers,class\\n'\n",
    "show_images = True\n",
    "features = []"
   ],
   "id": "ac9fab29b6e3ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract features",
   "id": "d8f5b7d7ef796734"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract featured from input images (base featured on difference in body parts and cloths color)\n",
    "for file in files:\n",
    "    try:\n",
    "        origin = cv.imread(str(file))\n",
    "        (H, W) = origin.shape[:2]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    mouth = pants = shoes = 0\n",
    "    tshirt = shorts = sneakers = 0\n",
    "    class_name = 0 if file.name.startswith('b') else 1\n",
    "\n",
    "    image = origin.copy()\n",
    "    for height in range(0, H):\n",
    "        for width in range(0, W):\n",
    "            B, G, R = (\n",
    "                image.item(height, width, 0),\n",
    "                image.item(height, width, 1),\n",
    "                image.item(height, width, 2)\n",
    "            )\n",
    "            # Home - brown mouth\n",
    "            if 70 <= B <= 185 and 140 <= G <= 185 and 175 <= R <= 215:\n",
    "                image[height, width] = [0, 255, 255]\n",
    "                mouth += 1\n",
    "            # Home - blue pants\n",
    "            if 150 <= B <= 180 and 98 <= G <= 120 and 0 <= R <= 90:\n",
    "                image[height, width] = [0, 255, 255]\n",
    "                pants += 1\n",
    "            # Home - gray shoes\n",
    "            if height > (H / 2): # Search only in the bottom part of image\n",
    "                if 25 <= B <= 45 and 25 <= G <= 45 and 25 <= R <= 45:\n",
    "                    image[height, width] = [0, 255, 255]\n",
    "                    shoes += 1\n",
    "            # Bart - orange t-shirt\n",
    "            if 11 <= B <= 22 and 85 <= G <= 105 and 240 <= R <= 255:\n",
    "                image[height, width] = [0, 255, 255]\n",
    "                tshirt += 1\n",
    "            # Bart - blue shorts\n",
    "            if 125 <= B <= 170 and 0 <= G <= 12 and 0 <= R <= 20:\n",
    "                image[height, width] = [0, 255, 255]\n",
    "                shorts += 1\n",
    "            # Bart - blue sneakers\n",
    "            if height > (H / 2): # Search only in the bottom part of image\n",
    "                if 125 <= B <= 170 and 0 <= G <= 12 and 0 <= R <= 20:\n",
    "                    image[height, width] = [0, 255, 255]\n",
    "                    sneakers += 1         \n",
    "       \n",
    "    mouth = round((mouth / (H * W)) * 100, 9)\n",
    "    pants = round((pants / (H * W)) * 100, 9)\n",
    "    shoes = round((shoes / (H * W)) * 100, 9)\n",
    "    tshirt = round((tshirt / (H * W)) * 100, 9)\n",
    "    shorts = round((shorts / (H * W)) * 100, 9)\n",
    "    sneakers = round((sneakers / (H * W)) * 100, 9)\n",
    "    \n",
    "    items = [mouth, pants, shoes, tshirt, shorts, sneakers, class_name]\n",
    "    features.append(items)\n",
    "    \n",
    "    export += (\",\".join(str(item) for item in items)) + '\\n'"
   ],
   "id": "12f12f5d8af53edb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save features into CSV file\n",
    "from common import CV_WORKAREA_DIR\n",
    "FEATURES_CSV_FILE = Path(CV_WORKAREA_DIR, 'home_bart.csv')\n",
    "with open(FEATURES_CSV_FILE, 'w') as file:\n",
    "    file.write(export)"
   ],
   "id": "fbba49975d2f73b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read saved featured from CSV file\n",
    "dataset = pd.read_csv(FEATURES_CSV_FILE)\n",
    "Xs = dataset.iloc[:, 0:6].values\n",
    "Ys = dataset.iloc[:, 6].values"
   ],
   "id": "9baa9fce2a341f5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split input dataset into train and test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(Xs, Ys, test_size=0.2, random_state=1)"
   ],
   "id": "f5f9a93a4baa9790",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Building and training the neural network",
   "id": "30bfc51517f524e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Input image shape has six column (we need only 6 inputs)\n",
    "inputs = Xs_train.shape[1]\n",
    "# Output classes is binary (0 - Bart, 1 - Homer)\n",
    "output_classes = 2\n",
    "# Calculates the amount of neurons in hidden layers \n",
    "hidden_neurons = int((inputs + output_classes) / 2)"
   ],
   "id": "ace3a839884b5c49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create NN\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.Input(shape=(inputs,)))\n",
    "model2.add(keras.layers.Dense(units=hidden_neurons, activation='relu'))\n",
    "model2.add(keras.layers.Dense(units=hidden_neurons, activation='relu'))\n",
    "model2.add(keras.layers.Dense(units=hidden_neurons, activation='relu'))\n",
    "model2.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model2.summary()"
   ],
   "id": "26fc1398e59ab08b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model2.fit(Xs_train, Ys_train, epochs=50, verbose=1)"
   ],
   "id": "38080aa851c3af8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluating NN",
   "id": "74082ce93e13852c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(history.history['loss']);",
   "id": "bc817f7a113814dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(history.history['accuracy']);",
   "id": "4611b5375b83346e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.subplot(Xs_train, Ys_train)\n",
    "\n",
    "predictions = model2.predict(Xs_test)\n",
    "predictions = (predictions > 0.5)"
   ],
   "id": "dfaf7100126fafde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Ys_test, predictions)"
   ],
   "id": "306350b3f646c8e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Ys_test, predictions)\n",
    "sns.heatmap(cm, annot=True);"
   ],
   "id": "8b44c03150dfca27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Ys_test, predictions))"
   ],
   "id": "b624d529359fde19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving, loading and classifying one single image",
   "id": "d3fac59d863ce38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from common import CV_WORKAREA_DIR\n",
    "\n",
    "MODEL_FILE = Path(CV_WORKAREA_DIR, 'home_bart2.json')\n",
    "MODEL_WEIGHTS_FILE = Path(CV_WORKAREA_DIR, 'home_bart2.keras')\n",
    "\n",
    "model_json = model2.to_json()\n",
    "with open(MODEL_FILE, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "keras.models.save_model(model2, MODEL_WEIGHTS_FILE)\n",
    "with open(MODEL_FILE) as json_file:\n",
    "    json_model = json_file.read()"
   ],
   "id": "b3326715adf0b40b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3 = keras.models.model_from_json(json_model)\n",
    "model3.load_weights(MODEL_WEIGHTS_FILE)\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ],
   "id": "df133afd38fcc1f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image = Xs_test[0] # Contains only features\n",
    "print(image)"
   ],
   "id": "c8f1d0e28fcb7f79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image = image.reshape(1, -1)\n",
    "prediction = model3.predict(image)\n",
    "if prediction < 0.5:\n",
    "    print('Bart')\n",
    "else:\n",
    "    print('Homer')"
   ],
   "id": "8d322fdb12250f6d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
