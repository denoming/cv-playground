{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TensorFlow: Overfit and underfit (L2 + Dropout)",
   "id": "635e043c2f08c909"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tempfile\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF Eager mode: \", tf.executing_eagerly())\n",
    "print(\"TF GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
   ],
   "id": "b890583bbb99f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare dataset",
   "id": "6acdb54cbe245593"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load \"higgs\" dataset\n",
    "whole_ds, ds_info= tfds.load(\"higgs\", with_info=True)"
   ],
   "id": "8ae39005330f6853",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "element = next(whole_ds[\"train\"].take(1).as_numpy_iterator())\n",
    "\n",
    "print(\"Data structure:\")\n",
    "print(f\"Keys: {list(element.keys())}\")\n",
    "print()\n",
    "print(f\"Values: {list(element.values())}\")"
   ],
   "id": "6063fd7c107adfff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the number of features (1 - label, 28 - features)\n",
    "N_FEATURES = len(ds_info.features) - 1\n",
    "# Define the size of validation dataset (limit)\n",
    "N_VALID = int(1e3)\n",
    "# Define the size of training dataset (limit)\n",
    "N_TRAIN = int(1e4)\n",
    "# Define the size of buffer for shuffling\n",
    "BUFFER_SIZE = int(1e4)\n",
    "# Define the size of batch size\n",
    "BATCH_SIZE = 1000\n",
    "# Define the number of steps per epoch\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE"
   ],
   "id": "1648214b043fc0c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Re-pack dataset in order to have the following element signature: (features, label)\n",
    "#\n",
    "\n",
    "def pack(elem):\n",
    "    values = list(elem.values())\n",
    "    label = values[:1]\n",
    "    feats = values[1:]\n",
    "    return feats, label\n",
    "\n",
    "val_ds = (whole_ds[\"train\"]\n",
    "          .take(N_VALID)\n",
    "          .cache()\n",
    "          .map(pack)\n",
    "          .batch(BATCH_SIZE)\n",
    "          .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "train_ds = (whole_ds[\"train\"]\n",
    "            .skip(N_VALID)\n",
    "            .take(N_TRAIN)\n",
    "            .cache()\n",
    "            .map(pack)\n",
    "            .shuffle(BUFFER_SIZE)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ],
   "id": "d6ad16649cecbaf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Demonstrate overfitting",
   "id": "14686eaf076c5e7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "size_histories = {}",
   "id": "ea535d64680ee9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_history(history, metrics=None):\n",
    "    if metrics is None:\n",
    "        metrics = [\"loss\", \"accuracy\"]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for metric in metrics:\n",
    "        plt.plot(\n",
    "            gaussian_filter1d(history.history[metric], sigma=2),\n",
    "            label=f\"{metric.capitalize()} (Train)\")\n",
    "        plt.plot(\n",
    "            gaussian_filter1d(history.history[f\"val_{metric}\"], sigma=2),\n",
    "            label=f\"{metric.capitalize()} (Validation)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "a37af08d1f47986f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compile_and_fit(model, optimizer, callbacks=None, max_epochs=1_000):\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.BinaryCrossentropy(from_logits=True),\n",
    "                 \"accuracy\"])\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=max_epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2)\n",
    "    return history"
   ],
   "id": "990462280274c3e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define callbacks",
   "id": "81cbce3c88a8c219"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* EarlyStopping - callback to avoid long and unnecessary training times\n",
    "* TensorBoard - callback to generate TensorBoard logs for the training"
   ],
   "id": "fd7f838f59224271"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "log_dir = pathlib.Path(tempfile.mkdtemp()) / \"tensorboard_logs\"\n",
    "shutil.rmtree(log_dir, ignore_errors=True)"
   ],
   "id": "82ceb44b3ed9477",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_binary_crossentropy\", patience=200),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir / name),\n",
    "    ]"
   ],
   "id": "c5350e0191c6ef19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define learning rate scheduler",
   "id": "e96d57afa0e03546"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define learning rate scheduler\n",
    "lr_scheduler = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    1e-3, # The starting learning rate at step\n",
    "    decay_steps=STEPS_PER_EPOCH*1_000, # A value representing how often to apply the decay\n",
    "    decay_rate=1, # The factor determining the strength of the decay\n",
    "    staircase=False) # True - the learning rate remains constant for `decay_steps` and then drops"
   ],
   "id": "c8f17057b4043af8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "step = np.linspace(0, 100_000)\n",
    "lr = lr_scheduler(step)\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(step, lr)\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.xlabel(\"Epoch\")\n",
    "_ = plt.ylabel(\"Learning Rate\")"
   ],
   "id": "31bc9d33d5ad626a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define optimizer",
   "id": "5842faf0a07ab7c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_optimizer(scheduler=None):\n",
    "    if scheduler is None:\n",
    "        scheduler = lr_scheduler\n",
    "    return tf.keras.optimizers.Adam(scheduler)"
   ],
   "id": "6ffac885636ed371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Try models without regularization",
   "id": "2da2c8e53296c9e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Small model",
   "id": "563dcdd93feaf227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "small_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.elu, input_shape=(N_FEATURES,)),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ],
   "id": "a024276228576e4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "size_histories[\"Small\"] = compile_and_fit(\n",
    "    small_model,\n",
    "    get_optimizer(),\n",
    "    get_callbacks(\"sizes/Small\"))"
   ],
   "id": "366d6ee74e9f8d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_history(size_histories[\"Small\"])",
   "id": "51258e100671cca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Medium model",
   "id": "fcf5cb43fd06132a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "medium_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.elu, input_shape=(N_FEATURES,)),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ],
   "id": "4f3f237b817b8c22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "size_histories[\"Medium\"] = compile_and_fit(\n",
    "    medium_model,\n",
    "    get_optimizer(),\n",
    "    get_callbacks(\"sizes/Medium\"))"
   ],
   "id": "4213acaaaee212c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_history(size_histories[\"Medium\"])",
   "id": "afafdee549f45829",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Large model",
   "id": "fc30638a392c9111"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "large_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.elu, input_shape=(N_FEATURES,)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ],
   "id": "751f364c91b0c828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "size_histories[\"Large\"] = compile_and_fit(\n",
    "    large_model,\n",
    "    get_optimizer(),\n",
    "    get_callbacks(\"sizes/Large\"))"
   ],
   "id": "735be45cd04a50f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_history(size_histories[\"Large\"])",
   "id": "560366e0a2b640e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot results",
   "id": "503d46dadd7f45cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* \"Small\" model - do not overfit\n",
    "* \"Medium\" model - **overfit**\n",
    "* \"Large\" model - **overfit**"
   ],
   "id": "15716ac0415120df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plotter.plot(size_histories)\n",
    "a = plt.xscale(\"log\")\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "plt.ylim([0.5, 0.7])\n",
    "plt.xlabel(\"Epochs [Log Scale]\")"
   ],
   "id": "8f23327d674150ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Open an embedded TensorBoard viewer\n",
    "%tensorboard --logdir {log_dir}/sizes"
   ],
   "id": "f37ed74e2a967beb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Try models with regularization",
   "id": "f7df23ea3068c219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Copy \"Small\" model logs to use as a baseline for comparison\n",
    "shutil.rmtree(log_dir/\"regularizers/Small\", ignore_errors=True)\n",
    "shutil.copytree(log_dir / \"sizes/Small\", log_dir / \"regularizers/Small\")\n",
    "\n",
    "regularizer_histories = {}\n",
    "regularizer_histories[\"Small\"] = size_histories[\"Small\"]"
   ],
   "id": "90ec437ed42f0dec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* L1 regularization: the cost added is proportional to the absolute value of the weights coefficients (pushes weights towards exactly zero, encouraging a sparce model)\n",
    "* L2 regularization: the cost added is proportional to the square of the value of the weights coefficients (penalize the weights parameters without making them sparce since the penalty goes to zero for small weights - more preferable type of regularization)"
   ],
   "id": "ab4f8330ba3c179d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### With L2 regularization",
   "id": "31a9df3d60e42e27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "l2_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "                          input_shape=(N_FEATURES,)),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ],
   "id": "602437ae8ff00659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regularizer_histories[\"l2\"] = compile_and_fit(\n",
    "    l2_model,\n",
    "    get_optimizer(),\n",
    "    get_callbacks(\"regularizers/l2\"))"
   ],
   "id": "d27ab719ef621be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### With Dropout regularization",
   "id": "f942d2b72544d68f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dropout_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu,\n",
    "                          input_shape=(N_FEATURES,)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ],
   "id": "4107967fc6a59776",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "regularizer_histories[\"dropout\"] = compile_and_fit(\n",
    "    dropout_model,\n",
    "    get_optimizer(),\n",
    "    get_callbacks(\"regularizers/dropout\"))"
   ],
   "id": "1869541f16e0092f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### With L2+Dropout regularization",
   "id": "7f7b414ee3977ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "                          activation=tf.nn.elu,\n",
    "                          input_shape=(N_FEATURES,)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "                          activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "                          activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "                          activation=tf.nn.elu),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ],
   "id": "3714ebe8cf3140ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "regularizer_histories[\"combined\"] = compile_and_fit(\n",
    "    combined_model,\n",
    "    get_optimizer(),\n",
    "    get_callbacks(\"regularizers/combined\"))"
   ],
   "id": "e5f474f22b00bceb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot results",
   "id": "590c3af2e3a0a43a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plotter.plot(regularizer_histories)\n",
    "a = plt.xscale(\"log\")\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "plt.ylim([0.5, 0.7])\n",
    "plt.xlabel(\"Epochs [Log Scale]\")\n",
    "\n",
    "# According to results the model with combined regularization (L2 + dropout) is the best so far."
   ],
   "id": "c6ab431196187d58",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
