{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"images/deep_neural_network.png\" style=\"width:1024px;height:768px;\">",
   "id": "9e1679ef3969ec6e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:42.309030Z",
     "start_time": "2025-06-08T12:43:42.032307Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "np.random.seed(1)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:42.884759Z",
     "start_time": "2025-06-08T12:43:42.883080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_costs(costs, learning_rate=0.0075):\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()"
   ],
   "id": "c06b333a6035f70c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize",
   "id": "387c868d79d2eeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Without Dropout",
   "id": "2174a2e3f776acf2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:44.456812Z",
     "start_time": "2025-06-08T12:43:44.454492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_parameters(layers):\n",
    "    \"\"\"\n",
    "    Wl - weight matrix of shape (layer_dims[l], layer_dims[l-1])\\n\n",
    "    bl - bias vector of shape (layer_dims[l], 1)\n",
    "    :param layer_dims: array (list) containing the dimensions of each layer\n",
    "    :return: dictionary containing the parameters of each layer: \"W1\", \"b1\", ..., \"WL\", \"bL\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    L = len(layers)\n",
    "    for l in range(1, L):\n",
    "        curr, prev = layers[l], layers[l-1]\n",
    "        dimsP = prev[\"dims\"]\n",
    "        dimsC, activC = curr[\"dims\"], curr[\"activation\"]\n",
    "        # Initialize all weights using \"He\"/\"Xavier\" initialization to eliminate vanishing/exploding gradients\n",
    "        parameters['W' + str(l)] = np.random.randn(dimsC, dimsP)\n",
    "        if activC == \"relu\":\n",
    "            parameters['W' + str(l)] *= np.sqrt(2 / dimsP)\n",
    "        elif activC == \"sigmoid\":\n",
    "            parameters['W' + str(l)] *= np.sqrt(1 / dimsP)\n",
    "        else:\n",
    "            parameters['W' + str(l)] *= 0.01\n",
    "        # Initialize all biases to zero\n",
    "        parameters['b' + str(l)] = np.zeros((dimsC, 1))\n",
    "    return parameters"
   ],
   "id": "5decec3ffeb76cd2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:46.186992Z",
     "start_time": "2025-06-08T12:43:46.184048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(1)\n",
    "t_parameters = initialize_parameters([\n",
    "\t{\"dims\": 5, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 4, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 3, \"activation\": \"relu\"},\n",
    "])\n",
    "assert np.allclose(t_parameters[\"W1\"], np.array([\n",
    "    [1.02732621, -0.38690873, -0.33404515, -0.67860494, 0.54733184],\n",
    "    [-1.45562088, 1.10351585, -0.48142952, 0.20177804,-0.15771567],\n",
    "    [0.92471825, -1.30294739, -0.20391454, -0.2428973, 0.71705876],\n",
    "    [-0.69563232, -0.10905317, -0.55520641, 0.02669832, 0.36860471]\n",
    "]))\n",
    "assert np.allclose(t_parameters[\"b1\"], np.array(\n",
    "    [0, 0, 0, 0]\n",
    "))\n",
    "assert np.allclose(t_parameters[\"W2\"], np.array([\n",
    "    [-0.77825528, 0.8094419, 0.63752091, 0.35531715],\n",
    "    [ 0.63700135, -0.48346861, -0.08689651, -0.66168891],\n",
    "    [-0.18942548, 0.37501795, -0.48907801, -0.28054711]\n",
    "]))\n",
    "assert np.allclose(t_parameters[\"b2\"], np.array([[0.]]))"
   ],
   "id": "460e7d313876909e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## With Dropout",
   "id": "401e3180155cc4fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:47.753380Z",
     "start_time": "2025-06-08T12:43:47.751036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_parameters_dropout(layers):\n",
    "    parameters = {}\n",
    "    L = len(layers)\n",
    "    for l in range(1, L):\n",
    "        curr, prev = layers[l], layers[l-1]\n",
    "        dimsP = prev[\"dims\"]\n",
    "        dimsC, keep_probsC, activC = curr[\"dims\"], curr[\"keep_prob\"], curr[\"activation\"]\n",
    "        parameters['W' + str(l)] = np.random.randn(dimsC, dimsP)\n",
    "        if activC == \"relu\":\n",
    "            parameters['W' + str(l)] *= np.sqrt(2 / dimsP)\n",
    "        elif activC == \"sigmoid\":\n",
    "            parameters['W' + str(l)] *= np.sqrt(1 / dimsP)\n",
    "        else:\n",
    "            parameters['W' + str(l)] *= 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((dimsC, 1))\n",
    "        parameters['keep_prob' + str(l)] = keep_probsC\n",
    "    return parameters"
   ],
   "id": "c920cbf74bd7962",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Forward propagation",
   "id": "91c3fdd1722d0279"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Common",
   "id": "ab4e8611d1b4b61c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:49.315341Z",
     "start_time": "2025-06-08T12:43:49.313636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation\n",
    "    :param Z: numpy array of any shape\n",
    "    :return: output of sigmoid(z), same shape as Z\n",
    "    \"\"\"\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache"
   ],
   "id": "b5db74f340bce00a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:50.359851Z",
     "start_time": "2025-06-08T12:43:50.358052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function\n",
    "    :param Z: Output of the linear layer, of any shape\n",
    "    :return:  output of relu(z), same shape as Z\n",
    "    \"\"\"\n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z\n",
    "    return A, cache"
   ],
   "id": "a41ba41f7c9ef5c8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:51.467301Z",
     "start_time": "2025-06-08T12:43:51.465614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "    :param A: activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    :param W: weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    :param b: bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    :return:\n",
    "        Z -- the input of the activation function, also called pre-activation parameter\n",
    "        cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    Z = W.dot(A) + b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache"
   ],
   "id": "d034fedf9e3fa68e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:52.666338Z",
     "start_time": "2025-06-08T12:43:52.664377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(1)\n",
    "t_A = np.random.randn(3,2)\n",
    "t_W = np.random.randn(1,3)\n",
    "t_b = np.random.randn(1,1)\n",
    "t_Z, t_linear_cache = linear_forward(t_A, t_W, t_b)\n",
    "assert np.allclose(t_Z, np.array([3.26295337, -1.23429987]))"
   ],
   "id": "b79103a0e69e3f92",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Forward (without dropout)",
   "id": "7ad1580d4c488c49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:54.129525Z",
     "start_time": "2025-06-08T12:43:54.127439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "    :param A_prev: activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    :param W: weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    :param b: bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    :param activation: the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    :return:\n",
    "        A -- the output of the activation function, also called the post-activation value\n",
    "        cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "    \"\"\"\n",
    "    A, linear_cache, activation_cache = None, None, None\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ],
   "id": "d3050cf481e6c9ca",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:55.622393Z",
     "start_time": "2025-06-08T12:43:55.619986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(1)\n",
    "t_A_prev = np.random.randn(3,2)\n",
    "t_W = np.random.randn(1,3)\n",
    "t_b = np.random.randn(1,1)\n",
    "t_A, t_linear_activation_cache = linear_activation_forward(t_A_prev, t_W, t_b, activation = \"sigmoid\")\n",
    "assert np.allclose(t_A, np.array([[0.96313579, 0.22542973]]));\n",
    "t_A, t_linear_activation_cache = linear_activation_forward(t_A_prev, t_W, t_b, activation = \"relu\")\n",
    "assert np.allclose(t_A, np.array([[3.26295337, 0.0]]));"
   ],
   "id": "a443fec0626799d8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:57.124696Z",
     "start_time": "2025-06-08T12:43:57.122572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagate(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2 # Number of layers in the neural network\n",
    "\n",
    "    # Implement [LINEAR->RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "\n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ],
   "id": "8484174c6a412fca",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:43:58.517728Z",
     "start_time": "2025-06-08T12:43:58.514915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(1)\n",
    "t_X = np.random.randn(5,4)\n",
    "t_parameters = {\n",
    "    \"W1\": np.random.randn(4,5),\n",
    "    \"b1\": np.random.randn(4,1),\n",
    "    \"W2\": np.random.randn(3,4),\n",
    "    \"b2\": np.random.randn(3,1),\n",
    "    \"W3\": np.random.randn(1,3),\n",
    "    \"b3\": np.random.randn(1,1)\n",
    "}\n",
    "t_AL, t_caches = forward_propagate(t_X, t_parameters)\n",
    "print(\"AL = \" + str(t_AL))\n",
    "assert np.allclose(t_AL, np.array([[0.77634609, 0.9998399, 0.99021857, 0.33755508]]))"
   ],
   "id": "a23e169e9445e216",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.77634609 0.9998399  0.99021857 0.33755508]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Forward (with dropout)",
   "id": "ecebe8fd6aae9f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:00.131840Z",
     "start_time": "2025-06-08T12:44:00.129596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_activation_forward_dropout(A_prev, W, b, keep_prob, activation):\n",
    "    A, linear_cache, activation_cache = None, None, None\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "\n",
    "    D = None\n",
    "    if keep_prob < 1.0:\n",
    "        D = np.random.rand(A.shape[0], A.shape[1])\n",
    "        D = (D < keep_prob).astype(int)\n",
    "        A = np.multiply(A, D)\n",
    "        A = A / keep_prob\n",
    "\n",
    "    cache = (linear_cache, activation_cache, D)\n",
    "    return A, cache"
   ],
   "id": "a5d60902cb51f400",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:01.686213Z",
     "start_time": "2025-06-08T12:44:01.683619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagate_dropout(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 3 # Number of layers in the neural network\n",
    "\n",
    "    # Implement [LINEAR->RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        W, b, keep_prob = parameters['W' + str(l)], parameters['b' + str(l)], parameters['keep_prob' + str(l)]\n",
    "        A, cache = linear_activation_forward_dropout(A_prev, W, b, keep_prob, activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "\n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    WL, bL, keep_probL = parameters['W' + str(L)], parameters['b' + str(L)], parameters['keep_prob' + str(L)]\n",
    "    AL, cache = linear_activation_forward_dropout(A, WL, bL, keep_probL, activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ],
   "id": "50f636cdc178e556",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cost function",
   "id": "721ae584741bcf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:02.940708Z",
     "start_time": "2025-06-08T12:44:02.938872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function\n",
    "    :param AL: probability vector corresponding to label predictions, shape (1, number of examples)\n",
    "    :param Y: true \"label\" vector\n",
    "    :return: cross-entropy cost\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ],
   "id": "b1ce9a75e8dcee78",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:03.871259Z",
     "start_time": "2025-06-08T12:44:03.869054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_Y = np.asarray([[1, 1, 0]])\n",
    "t_AL = np.array([[0.8, 0.9, 0.4]])\n",
    "t_cost = compute_cost(t_AL, t_Y)\n",
    "assert np.allclose(t_cost, 0.2797765635793422)"
   ],
   "id": "10f4fd829be9e49f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Backward propagation",
   "id": "10414c6d1d6d8a2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Common",
   "id": "9e99ffd08853a793"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:05.219874Z",
     "start_time": "2025-06-08T12:44:05.218234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ"
   ],
   "id": "d111bb470b32c5c3",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:07.136393Z",
     "start_time": "2025-06-08T12:44:07.134772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    return dZ"
   ],
   "id": "f683bb6d2bbd068e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:08.912581Z",
     "start_time": "2025-06-08T12:44:08.910403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db"
   ],
   "id": "327d27e19bd420c1",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:10.173462Z",
     "start_time": "2025-06-08T12:44:10.170315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(1)\n",
    "t_dZ = np.random.randn(3,4)\n",
    "t_linear_cache = (np.random.randn(5,4), np.random.randn(3,5), np.random.randn(3,1))\n",
    "t_dA_prev, t_dW, t_db = linear_backward(t_dZ, t_linear_cache)\n",
    "assert np.allclose(t_dA_prev, np.array([\n",
    "    [-1.15171336, 0.06718465, -0.3204696, 2.09812712],\n",
    "    [ 0.60345879, -3.72508701, 5.81700741, -3.84326836],\n",
    "    [-0.4319552, -1.30987417, 1.72354705, 0.05070578],\n",
    "    [-0.38981415, 0.60811244, -1.25938424, 1.47191593],\n",
    "    [-2.52214926, 2.67882552, -0.67947465, 1.48119548],\n",
    "]))\n",
    "assert np.allclose(t_dW, np.array([\n",
    "    [0.07313866, -0.0976715, -0.87585828, 0.73763362, 0.00785716],\n",
    "    [0.85508818, 0.37530413, -0.59912655, 0.71278189, -0.58931808],\n",
    "    [0.97913304, -0.24376494, -0.08839671, 0.55151192, -0.10290907],\n",
    "]))\n",
    "assert np.allclose(t_db, np.array([\n",
    "    [-0.14713786],\n",
    "    [-0.11313155],\n",
    "    [-0.13209101]\n",
    "]))"
   ],
   "id": "94ce7c376473b2d4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Backward (no dropout)",
   "id": "ada9cbaa5036fbd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:11.525859Z",
     "start_time": "2025-06-08T12:44:11.523504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l\n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def linear_activation_backward_dropout(dA, cache, activation):\n",
    "    linear_cache, activation_cache, _ = cache\n",
    "\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "    return dA_prev, dW, db"
   ],
   "id": "dff6636099c9c902",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:14.275399Z",
     "start_time": "2025-06-08T12:44:14.272475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(2)\n",
    "t_dAL = np.random.randn(1,2)\n",
    "t_A = np.random.randn(3,2)\n",
    "t_W = np.random.randn(1,3)\n",
    "t_b = np.random.randn(1,1)\n",
    "t_Z = np.random.randn(1,2)\n",
    "t_linear_activation_cache = ((t_A, t_W, t_b), t_Z)\n",
    "\n",
    "t_dA_prev, t_dW, t_db = linear_activation_backward(t_dAL, t_linear_activation_cache, activation = \"sigmoid\")\n",
    "assert np.allclose(t_dA_prev, np.array([\n",
    "    [0.11017994, 0.01105339],\n",
    "    [0.09466817, 0.00949723],\n",
    "    [-0.05743092, -0.00576154]\n",
    "]))\n",
    "assert np.allclose(t_dW, np.array([\n",
    "    [0.10266786, 0.09778551, -0.01968084]\n",
    "]))\n",
    "assert np.allclose(t_db, np.array([\n",
    "    [-0.05729622]\n",
    "]))\n",
    "\n",
    "t_dA_prev, t_dW, t_db = linear_activation_backward(t_dAL, t_linear_activation_cache, activation = \"relu\")\n",
    "assert np.allclose(t_dA_prev, np.array([\n",
    "    [0.44090989, 0.0],\n",
    "    [0.37883606, 0.0],\n",
    "    [-0.2298228, 0.0]\n",
    "]))\n",
    "assert np.allclose(t_dW, np.array([\n",
    "    [0.44513824, 0.37371418, -0.10478989]\n",
    "]))\n",
    "assert np.allclose(t_db, np.array([\n",
    "    [-0.20837892]\n",
    "]))"
   ],
   "id": "f55b269302607faf",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:16.450749Z",
     "start_time": "2025-06-08T12:44:16.448292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward_propagate(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
    "\n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ...\n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l+1)] = dW_temp\n",
    "        grads[\"db\" + str(l+1)] = db_temp\n",
    "\n",
    "    return grads"
   ],
   "id": "fecaa2dc24d5e936",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:18.442319Z",
     "start_time": "2025-06-08T12:44:18.438737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "t_AL = np.random.randn(1, 2)\n",
    "t_Y = np.array([[1, 0]])\n",
    "\n",
    "t_A1 = np.random.randn(4, 2)\n",
    "t_W1 = np.random.randn(3,4)\n",
    "t_b1 = np.random.randn(3,1)\n",
    "t_Z1 = np.random.randn(3,2)\n",
    "t_linear_cache_activation1 = ((t_A1, t_W1, t_b1), t_Z1)\n",
    "\n",
    "t_A2 = np.random.randn(3,2)\n",
    "t_W2 = np.random.randn(1,3)\n",
    "t_b2 = np.random.randn(1,1)\n",
    "t_Z2 = np.random.randn(1,2)\n",
    "t_linear_cache_activation2 = ((t_A2, t_W2, t_b2), t_Z2)\n",
    "\n",
    "t_AL, t_Y_assess, t_caches = t_AL, t_Y, (t_linear_cache_activation1, t_linear_cache_activation2)\n",
    "t_grads = backward_propagate(t_AL, t_Y_assess, t_caches)\n",
    "\n",
    "assert np.allclose(t_grads['dA0'], np.array([\n",
    "    [0.0, 0.52257901],\n",
    "    [0.0, -0.3269206],\n",
    "    [0.0, -0.32070404],\n",
    "    [0.0, -0.74079187]\n",
    "]))\n",
    "assert np.allclose(t_grads['dA1'], np.array([\n",
    "    [0.12913162, -0.44014127],\n",
    "    [-0.14175655, 0.48317296],\n",
    "    [0.01663708, -0.05670698]\n",
    "]))\n",
    "assert np.allclose(t_grads['dW1'], np.array([\n",
    "    [0.41010002, 0.07807203, 0.13798444, 0.10502167],\n",
    "    [0.0, 0.0, 0.0, 0.0],\n",
    "    [0.05283652, 0.01005865, 0.01777766, 0.0135308 ],\n",
    "]))\n",
    "assert np.allclose(t_grads['dW2'], np.array([\n",
    "    [-0.39202432, -0.13325855, -0.04601089]\n",
    "]))\n",
    "assert np.allclose(t_grads['db1'], np.array([\n",
    "    [-0.22007063],\n",
    "    [0.0],\n",
    "    [-0.02835349]\n",
    "]))\n",
    "assert np.allclose(t_grads['db2'], np.array([\n",
    "    [0.15187861]\n",
    "]))"
   ],
   "id": "d677715e675b67b9",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear Backward (with dropout)",
   "id": "1e0eecefdecee41f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:20.967177Z",
     "start_time": "2025-06-08T12:44:20.964177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward_propagate_dropout(AL, Y, parameters, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "\n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1-Y, 1-AL))\n",
    "    keep_probL = parameters[\"keep_prob\" + str(L)]\n",
    "    if keep_probL < 1.0:\n",
    "        _, _, D = caches[L-1]\n",
    "        dAL = np.multiply(dAL, D)\n",
    "        dAL = dAL / keep_probL\n",
    "\n",
    "    curr_cache = caches[L-1]\n",
    "    dA_prev, dW, db = linear_activation_backward_dropout(dAL, curr_cache, activation = \"sigmoid\")\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = (dA_prev, dW, db)\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        curr_cache = caches[l]\n",
    "        dA_prev, dW, db = linear_activation_backward_dropout(grads[\"dA\" + str(l+1)], curr_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)], grads[\"dW\" + str(l+1)], grads[\"db\" + str(l+1)] = (dA_prev, dW, db)\n",
    "\n",
    "    for l in reversed(range(1, L)):\n",
    "        keep_prob = parameters[\"keep_prob\" + str(l)]\n",
    "        if keep_prob < 1.0:\n",
    "            _, _, D = caches[l-1]\n",
    "            dAl = grads[\"dA\" + str(l)]\n",
    "            dAl = np.multiply(dAl, D)\n",
    "            dAl = dAl / keep_prob\n",
    "            grads[\"dA\" + str(l)] = dAl\n",
    "\n",
    "    return grads"
   ],
   "id": "df839358373dd610",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Update parameters",
   "id": "4cfc915e5aea7a75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Update parameters (without dropout)",
   "id": "ff8136673234adac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:23.105581Z",
     "start_time": "2025-06-08T12:44:23.103450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters\n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters\n",
    "                  parameters[\"W\" + str(l)] = ...\n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    parameters = copy.deepcopy(params)\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    return parameters"
   ],
   "id": "d26002ab614d98b1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:25.379876Z",
     "start_time": "2025-06-08T12:44:25.377027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(2)\n",
    "t_W1 = np.random.randn(3,4)\n",
    "t_b1 = np.random.randn(3,1)\n",
    "t_W2 = np.random.randn(1,3)\n",
    "t_b2 = np.random.randn(1,1)\n",
    "t_parameters = {\"W1\": t_W1,\n",
    "                \"b1\": t_b1,\n",
    "                \"W2\": t_W2,\n",
    "                \"b2\": t_b2}\n",
    "\n",
    "np.random.seed(3)\n",
    "t_dW1 = np.random.randn(3,4)\n",
    "t_db1 = np.random.randn(3,1)\n",
    "t_dW2 = np.random.randn(1,3)\n",
    "t_db2 = np.random.randn(1,1)\n",
    "t_grads = {\"dW1\": t_dW1,\n",
    "           \"db1\": t_db1,\n",
    "           \"dW2\": t_dW2,\n",
    "           \"db2\": t_db2}\n",
    "t_parameters = update_parameters(t_parameters, t_grads, 0.1)\n",
    "\n",
    "assert np.allclose(t_parameters[\"W1\"], np.array([\n",
    "    [-0.59562069, -0.09991781, -2.14584584, 1.82662008],\n",
    "    [-1.76569676, -0.80627147, 0.51115557, -1.18258802],\n",
    "    [-1.0535704, -0.86128581, 0.68284052, 2.20374577]\n",
    "]))\n",
    "assert np.allclose(t_parameters[\"b1\"], np.array([\n",
    "    [-0.04659241],\n",
    "    [-1.28888275],\n",
    "    [0.53405496]\n",
    "]))\n",
    "assert np.allclose(t_parameters[\"W2\"], np.array([\n",
    "    [-0.55569196, 0.0354055, 1.32964895]\n",
    "]))\n",
    "assert np.allclose(t_parameters[\"b2\"], np.array([\n",
    "    [-0.84610769]\n",
    "]))"
   ],
   "id": "fd838eaa60909e51",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Update parameters (with dropout)",
   "id": "b6e944017016fad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:27.934697Z",
     "start_time": "2025-06-08T12:44:27.932855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_parameters_dropout(params, grads, learning_rate):\n",
    "    parameters = copy.deepcopy(params)\n",
    "    L = len(parameters) // 3\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    return parameters"
   ],
   "id": "b173d8883177264b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "a0b255e0e4bb1326"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:29.993128Z",
     "start_time": "2025-06-08T12:44:29.917618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "from common import CV_DATA_DIR"
   ],
   "id": "85f1d7647f1c1549",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:30.702323Z",
     "start_time": "2025-06-08T12:44:30.700230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File(CV_DATA_DIR / \"playground\" / \"dnn\" / \"train_catvnoncat.h5\", \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File(CV_DATA_DIR / \"playground\" / \"dnn\" / \"test_catvnoncat.h5\", \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ],
   "id": "b47814d4d1ea5ddc",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:32.437115Z",
     "start_time": "2025-06-08T12:44:32.389678Z"
    }
   },
   "cell_type": "code",
   "source": "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()",
   "id": "8b0fac50f4cdd9e9",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:33.859983Z",
     "start_time": "2025-06-08T12:44:33.857881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print (\"Number of training examples:\", train_x_orig.shape[0])\n",
    "print (\"Number of testing examples:\", test_x_orig.shape[0])\n",
    "print (\"Each image is of size: (\" + str(train_x_orig.shape[1]) + \", \" + str(train_x_orig.shape[1]) + \", 3)\")\n",
    "\n",
    "assert train_x_orig.shape == (209, 64, 64, 3)\n",
    "assert train_y.shape == (1, 209)\n",
    "assert test_x_orig.shape == (50, 64, 64, 3)\n",
    "assert test_y.shape == (1, 50)"
   ],
   "id": "a0357974981bd6fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 209\n",
      "Number of testing examples: 50\n",
      "Each image is of size: (64, 64, 3)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:35.190664Z",
     "start_time": "2025-06-08T12:44:35.184997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape the training and test examples\n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print(\"train_x's shape: \" + str(train_x.shape))\n",
    "print(\"test_x's shape: \" + str(test_x.shape))"
   ],
   "id": "fb1cacb5af286809",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train L-layer model",
   "id": "9dd9c9e0bbc54fd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train L-layer Model (without dropout)",
   "id": "9ef987cdffdad827"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:39.629807Z",
     "start_time": "2025-06-08T12:44:39.628005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.0075\n",
    "\n",
    "layers_config = [\n",
    "\t{\"dims\": 12288, \"activation\": None},\n",
    "\t{\"dims\": 20, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 7, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 5, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 1, \"activation\": \"sigmoid\"},\n",
    "]"
   ],
   "id": "5ec28d71255f185a",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:44:40.759774Z",
     "start_time": "2025-06-08T12:44:40.757520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def L_layer_model(X, Y, layers, learning_rate = 0.0075, num_iterations = 3500, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    parameters = initialize_parameters(layers)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = forward_propagate(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = backward_propagate(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if print_cost and (i % 100 == 0 or i == num_iterations - 1):\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    return parameters, costs"
   ],
   "id": "2557736fb8cfb5c1",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:45:05.244475Z",
     "start_time": "2025-06-08T12:44:42.192552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parameters, costs = L_layer_model(\n",
    "    train_x, train_y,\n",
    "    layers_config,\n",
    "    learning_rate,\n",
    "    num_iterations = 4500,\n",
    "    print_cost = True)"
   ],
   "id": "d1bb96e07147bb37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.0081445907083524\n",
      "Cost after iteration 100: 0.6759653401043519\n",
      "Cost after iteration 200: 0.664907102637664\n",
      "Cost after iteration 300: 0.657556288283337\n",
      "Cost after iteration 400: 0.6526602719800702\n",
      "Cost after iteration 500: 0.649238912006134\n",
      "Cost after iteration 600: 0.6467162744881768\n",
      "Cost after iteration 700: 0.6446557808185854\n",
      "Cost after iteration 800: 0.6425085221335521\n",
      "Cost after iteration 900: 0.6403881228483663\n",
      "Cost after iteration 1000: 0.6384291123880995\n",
      "Cost after iteration 1100: 0.6364439655178741\n",
      "Cost after iteration 1200: 0.6340904612892516\n",
      "Cost after iteration 1300: 0.6315491637520989\n",
      "Cost after iteration 1400: 0.628492444199776\n",
      "Cost after iteration 1500: 0.6247493591369389\n",
      "Cost after iteration 1600: 0.6200676283988742\n",
      "Cost after iteration 1700: 0.6137058237143043\n",
      "Cost after iteration 1800: 0.6073967042509079\n",
      "Cost after iteration 1900: 0.5994876506445569\n",
      "Cost after iteration 2000: 0.5939265919333917\n",
      "Cost after iteration 2100: 0.586019877610374\n",
      "Cost after iteration 2200: 0.5650884448918425\n",
      "Cost after iteration 2300: 0.5318456560854982\n",
      "Cost after iteration 2400: 0.47200847095245146\n",
      "Cost after iteration 2500: 0.36752167715734446\n",
      "Cost after iteration 2600: 0.3225014802376668\n",
      "Cost after iteration 2700: 0.5710106736938716\n",
      "Cost after iteration 2800: 0.1371837857839284\n",
      "Cost after iteration 2900: 0.08764067335259705\n",
      "Cost after iteration 3000: 0.4466243783670908\n",
      "Cost after iteration 3100: 0.16462506862745602\n",
      "Cost after iteration 3200: 0.23433875197320314\n",
      "Cost after iteration 3300: 0.07399694473746907\n",
      "Cost after iteration 3400: 0.05305529615791699\n",
      "Cost after iteration 3500: 0.04309432690924033\n",
      "Cost after iteration 3600: 0.03715416557893617\n",
      "Cost after iteration 3700: 0.03318230119263152\n",
      "Cost after iteration 3800: 0.03027174084189391\n",
      "Cost after iteration 3900: 0.028090307939788783\n",
      "Cost after iteration 4000: 0.02639042932063365\n",
      "Cost after iteration 4100: 0.025042529739702026\n",
      "Cost after iteration 4200: 0.02396156022408929\n",
      "Cost after iteration 4300: 0.023029727311697903\n",
      "Cost after iteration 4400: 0.022242244649184527\n",
      "Cost after iteration 4499: 0.021546728087541312\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:45:06.506055Z",
     "start_time": "2025-06-08T12:45:06.458181Z"
    }
   },
   "cell_type": "code",
   "source": "plot_costs(costs, learning_rate)",
   "id": "f320a01b93f03f9a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAGJCAYAAAAKUHMeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU35JREFUeJzt3XlcVOX+B/DPLMwMAwyyDqAI7vuKSWSLKYUtdvW2Xa00Nb2WWmrda16vom20561M0/bfzbQs2zSXvGpu5YKYlvuKC5vsDDAw8/z+GObACAwDDAwzfN6vFy+ZM+eceTgZH5/nPM/3yIQQAkRERFQjuasbQERE1JIxKImIiOxgUBIREdnBoCQiIrKDQUlERGQHg5KIiMgOBiUREZEdDEoiIiI7GJRERER2MCiJGik6OhqPPvqoq5tBRE2EQUktwieffAKZTIb9+/e7uimtisFgwMKFC7Ft2zZXN8XGhx9+iB49ekCj0aBLly545513HD62tLQUc+bMQUREBLy9vREbG4vNmzfXuO/u3btx4403QqvVIiwsDE8++SQKCwtt9nn00Uchk8lq/bp06ZK079ChQ2vcZ8SIEQ27ENQiKF3dACJ3d/z4ccjl7vlvToPBgEWLFgGw/JJvCd5//31MnToV9957L2bPno0dO3bgySefhMFgwJw5c+o8/tFHH8WaNWswc+ZMdOnSBZ988gnuvPNObN26FTfeeKO0X0pKCoYPH44ePXrgzTffxMWLF/H666/j5MmT+Omnn6T9/v73vyM+Pt7mM4QQmDp1KqKjo9G2bVub99q1a4ekpCSbbREREQ25FNRSCKIW4OOPPxYAxL59+1zajrKyMlFaWurSNjRGfdufmZkpAIjExMSma1Q9GAwGERQUJO666y6b7Q899JDw8fER2dnZdo//7bffBADx2muvSduKi4tFp06dRFxcnM2+d9xxhwgPDxd5eXnSthUrVggAYuPGjXY/Z8eOHQKAePHFF22233LLLaJXr152jyX3457/DKZW69KlS5g4cSL0ej3UajV69eqFjz76yGYfo9GIBQsWICYmBv7+/vDx8cFNN92ErVu32ux37tw5yGQyvP7661i8eDE6deoEtVqNP//8EwsXLoRMJsOpU6fw6KOPok2bNvD398eECRNgMBhsznPtPUrrMPKuXbswe/ZshISEwMfHB6NHj0ZmZqbNsWazGQsXLkRERAS0Wi1uvfVW/Pnnnw7d97TXfkeuwblz5xASEgIAWLRokTRMuHDhQmmfY8eO4b777kNgYCA0Gg0GDRqE77//vq7/TA22detWXL16FU888YTN9mnTpqGoqAjr1q2ze/yaNWugUCgwZcoUaZtGo8GkSZOwZ88epKamAgDy8/OxefNmPPzww9DpdNK+48aNg6+vL7788ku7n7Ny5UrIZDKMHTu2xvfLy8urDeGS++LQK7mN9PR0XH/99ZDJZJg+fTpCQkLw008/YdKkScjPz8fMmTMBWH4JfvDBBxgzZgwmT56MgoICfPjhh0hISMDevXvRv39/m/N+/PHHKCkpwZQpU6BWqxEYGCi998ADD6BDhw5ISkpCcnIyPvjgA4SGhuKVV16ps70zZsxAQEAAEhMTce7cOSxevBjTp0/H6tWrpX3mzp2LV199FSNHjkRCQgIOHTqEhIQElJSUOHxdamq/I9cgJCQES5cuxeOPP47Ro0fjr3/9KwCgb9++AIA//vgDQ4YMQdu2bfHss8/Cx8cHX375JUaNGoWvv/4ao0ePttuunJwcmEymOtuv1Wqh1WoBAAcPHgQADBo0yGafmJgYyOVyHDx4EA8//HCt5zp48CC6du1qE34AMHjwYACW4dbIyEgcPnwY5eXl1T5HpVKhf//+UjtqUlZWhi+//BI33HADoqOjq71/4sQJ+Pj4wGg0Qq/XY/LkyViwYAG8vLxqvwjUsrm6S0skhGNDr5MmTRLh4eEiKyvLZvvf/vY34e/vLwwGgxBCiPLy8mrDjzk5OUKv14uJEydK286ePSsACJ1OJzIyMmz2T0xMFABs9hdCiNGjR4ugoCCbbVFRUWL8+PHVfpb4+HhhNpul7bNmzRIKhULk5uYKIYRIS0sTSqVSjBo1yuZ8CxcuFABszlkTe+139BrYG3odPny46NOnjygpKZG2mc1mccMNN4guXbrYbZsQlusCoM6vqp89bdo0oVAoajxfSEiI+Nvf/mb3M3v16iWGDRtWbfsff/whAIhly5YJIYT46quvBADxyy+/VNv3/vvvF2FhYbV+xg8//CAAiPfee6/aexMnThQLFy4UX3/9tfjss8/EPffcIwCIBx54wG67qWVjj5LcghACX3/9NR544AEIIZCVlSW9l5CQgFWrViE5ORlDhgyBQqGAQqEAYBnazM3NhdlsxqBBg5CcnFzt3Pfee680BHmtqVOn2ry+6aabsHbtWuTn51frtVxrypQpkMlkNse+9dZbOH/+PPr27YstW7agvLy82jDjjBkzbIY/61JT++t7Da6VnZ2N//3vf3juuedQUFCAgoIC6b2EhAQkJibi0qVL1SayVPX555+juLi4zs/q2LGj9H1xcTFUKlWN+2k0mjrPV1xcDLVaXeOx1ver/lnbvvY+Z+XKlfDy8sIDDzxQ7b0PP/zQ5vUjjzyCKVOmYMWKFZg1axauv/56u+2nlolBSW4hMzMTubm5WL58OZYvX17jPhkZGdL3n376Kd544w0cO3YMZWVl0vYOHTpUO66mbVbt27e3eR0QEADAMqxYV1DaOxYAzp8/DwDo3LmzzX6BgYHSvo6orf31uQbXOnXqFIQQmD9/PubPn1/jPhkZGXaDcsiQIXV+zrW8vb1hNBprfK+kpATe3t51Hl9aWlrjsdb3q/5Z2761fU5hYSG+++47JCQkICgoyG5brJ5++mmsWLECP//8M4PSTTEoyS2YzWYAwMMPP4zx48fXuI/13tp///tfPProoxg1ahT+8Y9/IDQ0FAqFAklJSTh9+nS14+z98rX2yq4lhKizzY05tj5qan99r8G1rNf7mWeeQUJCQo37XBvw18rMzHToHqWvry98fX0BAOHh4TCZTMjIyEBoaKi0j9FoxNWrV+tcZhEeHm6zrtHqypUrACqXaYSHh9tsv3bf2j7n22+/hcFgwEMPPVTnz2UVGRkJwNJLJ/fEoCS3EBISAj8/P5hMpmpr2q61Zs0adOzYEd98843N0GdiYmJTN7NeoqKiAFh6b1V7eVevXpV6nQ3l6DWo+l5V1uFQLy+vOq93ba677jqp12xPYmKiNNRsnWi1f/9+3HnnndI++/fvh9lsrjYR61r9+/fH1q1bqw2N//bbbzbn7927N5RKJfbv328zhGo0GpGSklLjsCpgGU729fXFPffcU+fPZXXmzBkAqHV4n1o+Lg8ht6BQKHDvvffi66+/xpEjR6q9X3XZhbUnV7Xn9ttvv2HPnj1N39B6GD58OJRKJZYuXWqz/d133230uR29BtbZprm5uTbbQ0NDMXToULz//vs19rquXeZSk88//xybN2+u82vcuHHSMcOGDUNgYGC1a7J06VJotVrcdddd0rasrCwcO3bMZrnOfffdB5PJZDM8X1paio8//hixsbFS787f3x/x8fH473//a3P/9f/+7/9QWFiI+++/v8af+eeff8bo0aOl61ZVfn5+taFcIQReeOEFAKi1Z04tH3uU1KJ89NFH2LBhQ7XtTz31FF5++WVs3boVsbGxmDx5Mnr27Ins7GwkJyfj559/loa27r77bnzzzTcYPXo07rrrLpw9exbLli1Dz549W9TaNr1ej6eeegpvvPEG7rnnHowYMQKHDh3CTz/9hODg4Fp7e45w9Bp4e3ujZ8+eWL16Nbp27YrAwED07t0bvXv3xpIlS3DjjTeiT58+mDx5Mjp27Ij09HTs2bMHFy9exKFDh+y2oaH3KJ9//nlMmzYN999/PxISErBjxw7897//xYsvvmizdOfdd9/FokWLsHXrVqmqUGxsLO6//37MnTsXGRkZ6Ny5Mz799FOcO3eu2kSbF198ETfccANuueUWTJkyBRcvXsQbb7yB22+/vcaSc6tXr0Z5eXmtw67JyckYM2YMxowZg86dO6O4uBhr167Frl27MGXKFAwcOLDe14NaCNdNuCWqZF1SUdtXamqqEEKI9PR0MW3aNBEZGSm8vLxEWFiYGD58uFi+fLl0LrPZLF566SURFRUl1Gq1GDBggPjxxx/F+PHjRVRUlLSfdXlF1SouVtblIZmZmTW28+zZs9K22paHXLvUZevWrQKA2Lp1q7StvLxczJ8/X4SFhQlvb28xbNgwcfToUREUFCSmTp1q95rZa7+j10AIIXbv3i1iYmKESqWqtlzj9OnTYty4cSIsLEx4eXmJtm3birvvvlusWbPGbtsaa/ny5aJbt25CpVKJTp06ibfeestmqY0Qlf+Nql5PISyVeJ555hkRFhYm1Gq1uO6668SGDRtq/JwdO3aIG264QWg0GhESEiKmTZsm8vPza9z3+uuvF6GhoaK8vLzG98+cOSPuv/9+ER0dLTQajdBqtSImJkYsW7asWtvJvciEcPLMAiJqlNzcXAQEBOCFF17AvHnzXN0colaP9yiJXKim9XqLFy8G0HKKlBO1drxHSeRCq1evlp5u4evri507d+KLL77A7bff3qB7fETkfAxKIhfq27cvlEolXn31VeTn50sTfKwzJYnI9XiPkoiIyA7eoyQiIrKDQUlERGRHq7tHaTabcfnyZfj5+TVqQTcREbk3IQQKCgoQEREBubz2fmOrC8rLly9LZayIiIhSU1PRrl27Wt9vdUHp5+cHwHJh6npMEhERea78/HxERkZKuVCbVheU1uFWnU7HoCQiojpvw3EyDxERkR0MSiIiIjsYlERERHYwKImIiOxgUBIREdnBoCQiIrKDQUlERGQHg5KIiMgOBiUREZEdLg3KX375BSNHjkRERARkMhm+/fbbOo/Ztm0bBg4cCLVajc6dO+OTTz5p8nZeq6CkDP87lo4NR9Ka/bOJiKh5uTQoi4qK0K9fPyxZssSh/c+ePYu77roLt956K1JSUjBz5kw89thj2LhxYxO31Nal3GJM/GQ/5q093KyfS0REzc+ltV7vuOMO3HHHHQ7vv2zZMnTo0AFvvPEGAKBHjx7YuXMn3nrrLSQkJDRVM6sJ8lEDALINRpjMAgo5H9dFROSp3Ooe5Z49exAfH2+zLSEhAXv27Kn1mNLSUuTn59t8NVaA1gsyGSAEkGMwNvp8RETUcrlVUKalpUGv19ts0+v1yM/PR3FxcY3HJCUlwd/fX/pyxrMolQo52nh7AQCyixiURESezK2CsiHmzp2LvLw86Ss1NdUp5w3ytQy/ZhWWOuV8RETUMrnV8yjDwsKQnp5usy09PR06nQ7e3t41HqNWq6FWq53eliAfFU4BuFrIHiURkSdzqx5lXFwctmzZYrNt8+bNiIuLa/a2BPmqAABX2aMkIvJoLg3KwsJCpKSkICUlBYBl+UdKSgouXLgAwDJsOm7cOGn/qVOn4syZM/jnP/+JY8eO4b333sOXX36JWbNmNXvbpZmvvEdJROTRXBqU+/fvx4ABAzBgwAAAwOzZszFgwAAsWLAAAHDlyhUpNAGgQ4cOWLduHTZv3ox+/frhjTfewAcffNCsS0OsrD3KLAYlEZFHc+k9yqFDh0IIUev7NVXdGTp0KA4ePNiErXKMdTIPh16JiDybW92jbEmCfCw9Sg69EhF5NgZlA1mDkrNeiYg8G4OygbiOkoiodWBQNlBwxWSe/JJyGMvNLm4NERE1FQZlA+k0XlIxdNZ7JSLyXAzKBpLLZQisuE/J4VciIs/FoGwETughIvJ8DMpGkMrYFbFHSUTkqRiUjWAtY8ceJRGR52JQNkJlj5JBSUTkqRiUjRDMMnZERB6PQdkIgSxjR0Tk8RiUjRAkLQ9hUBIReSoGZSNITxDhrFciIo/FoGwEaxk7znolIvJcDMpGsN6jNBhNKDaaXNwaIiJqCgzKRvBVK6FSWi4hh1+JiDwTg7IRZDIZglnGjojIozEoGymQZeyIiDwag7KRWMaOiMizMSgbiWXsiIg8G4OykVjGjojIszEoG8m6RIQ9SiIiz8SgbCQ+vJmIyLMxKBspmGXsiIg8GoOykQLZoyQi8mgMykaqOutVCOHi1hARkbMxKBvJuo7SWG5GYWm5i1tDRETOxqBsJG+VAj4qBQAOvxIReSIGpROwjB0RkediUDoBy9gREXkuBqUTBLOMHRGRx2JQOkFlj5JDr0REnoZB6QSB7FESEXksBqUTsIwdEZHnYlA6AcvYERF5LgalE7CMHRGR52JQOgEf3kxE5LkYlE5gHXrNLjLCbGa9VyIiT8KgdIIAraVHaTIL5BWXubg1RETkTAxKJ1Ap5dBplAA4/EpE5GkYlE4izXxl0QEiIo/CoHQSTughIvJMDEonYRk7IiLPxKB0EpaxIyLyTAxKJwlm0QEiIo/k8qBcsmQJoqOjodFoEBsbi71799rdf/HixejWrRu8vb0RGRmJWbNmoaSkpJlaW7sglrEjIvJILg3K1atXY/bs2UhMTERycjL69euHhIQEZGRk1Lj/ypUr8eyzzyIxMRFHjx7Fhx9+iNWrV+Nf//pXM7e8OmsZuyz2KImIPIpLg/LNN9/E5MmTMWHCBPTs2RPLli2DVqvFRx99VOP+u3fvxpAhQzB27FhER0fj9ttvx5gxY+rshTYH66zXbN6jJCLyKC4LSqPRiAMHDiA+Pr6yMXI54uPjsWfPnhqPueGGG3DgwAEpGM+cOYP169fjzjvvrPVzSktLkZ+fb/PVFLiOkojIMyld9cFZWVkwmUzQ6/U22/V6PY4dO1bjMWPHjkVWVhZuvPFGCCFQXl6OqVOn2h16TUpKwqJFi5za9ppYn0mZYyhDuckMpcLlt3+JiMgJ3Oq3+bZt2/DSSy/hvffeQ3JyMr755husW7cOzz//fK3HzJ07F3l5edJXampqk7StjVYFmczyfY6B9V6JiDyFy3qUwcHBUCgUSE9Pt9menp6OsLCwGo+ZP38+HnnkETz22GMAgD59+qCoqAhTpkzBvHnzIJdXz321Wg21Wu38H+AaCrkMgVoVrhYZcbWoFCF+Tf+ZRETU9FzWo1SpVIiJicGWLVukbWazGVu2bEFcXFyNxxgMhmphqFAoAABCuP7xVlIZO858JSLyGC7rUQLA7NmzMX78eAwaNAiDBw/G4sWLUVRUhAkTJgAAxo0bh7Zt2yIpKQkAMHLkSLz55psYMGAAYmNjcerUKcyfPx8jR46UAtOVKpeIcEIPEZGncGlQPvjgg8jMzMSCBQuQlpaG/v37Y8OGDdIEnwsXLtj0IP/9739DJpPh3//+Ny5duoSQkBCMHDkSL774oqt+BBtBVR7gTEREnkEmWsKYZTPKz8+Hv78/8vLyoNPpnHruxO+O4NM95zH91s54JqGbU89NRETO5WgeuNWs15aOZeyIiDwPg9KJWMaOiMjzMCidKJhl7IiIPA6D0omCWMaOiMjjMCidKIjPpCQi8jgMSicK8rH0KAtKy1FabnJxa4iIyBkYlE6k81ZCKbcUfOV9SiIiz8CgdCKZTMYydkREHoZB6WSBFcOvLGNHROQZGJROxiUiRESehUHpZJz5SkTkWRiUTmZdS5nFMnZERB6BQelk1jJ22exREhF5BAalk1nvUV7lPUoiIo/AoHQya9EBlrEjIvIMDEons66j5BNEiIg8A4PSyaw9Si4PISLyDAxKJ7P2KIvLTDAYy13cGiIiaiwGpZNpVQpovCyXlWspiYjcH4PSyWQymTT8yjJ2RETuj0HZBIJYxo6IyGMwKJsAy9gREXkOBmUTYBk7IiLPwaBsAkEsY0dE5DEYlE0giGXsiIg8BoOyCXDWKxGR52BQNoFAX07mISLyFAzKJhBc0aM8d7UIH+86i1wDA5OIyF0xKJtAhxAfBPmoYDCasOiHPzH4pS14atVB7D6dBSGEq5tHRET1IBOt7Dd3fn4+/P39kZeXB51O12Sfk1dchu9SLuGLvak4eiVf2h4dpMUD10Xivph2CPXTNNnnExGRfY7mAYOyiQkhcORSPr7YdwHfp1xGYamlULpCLsMNnYIwpHMwhnQKRs8IHRRyWZO3h4iILBiUtWjuoKzKYCzHj79fwep9qThwPsfmPX9vL8R1DMINnYNwQ6dgdArxgUzG4CQiaioMylq4MiirOpVRiF9OZGL36Sz8eiZb6mla6XVqxEQFoJteh25hvugWpkP7QC17nURETsKgrEVLCcqqyk1m/H4pD3tOX8WuU1nYfz4HxnJztf3USjm66H2l8OwY7Iu2Ad5oG+ANncbLBS0nInJfDMpatMSgvFZJmQnJ53Pwx+V8HE8vwPG0ApzMKEBJWfXwtPLTKNG2jTfaBXhX/KmF3l+DYF8VQnzVCPZVw9/bC3L2SImIADAoa+UOQVkTk1ngQrYBx9MKcKIiPM9nF+FSTjFyDGUOnUMplyHQR4VgXzWC/dQI8lGhjdYLAVrLn220KrTxrnwd4KOCj0rBe6VE5JEYlLVw16C0p6i0HJdzi3ExtxiXcopxqeLP9PwSZBWWIqvQiLxix8L0Wl4KGQK0KgRWhGqgjwoBWpUUptbX1sAN8FFBp1EyXImoxXM0D5TN2CZqIj5qJbro/dBF71frPsZyM7KLjMgqLEVmYSmyCkqRYzAix1CGXIMRuYYy5FT8af2+tNyMMpNARkEpMgocr1urkMvQxttL6qX6e3uhjbcX/LVeaOOtgr+30rJd61Wxn6Unq/P24mQlImpxGJSthEopR5i/BmH+jhc5KDaakG0wIqfIKIWq9H1RxWuD9bXle4PRBJNZ4GqRseLpKUX1aqdOYwlRa8gG+1h6s4G+KgT7qBHoo0KQrwpBPmoE+6mgVfGvMBE1Lf6WoVp5qxRoq7JMDnJUabkJuYYyZBdZeqd5xZZh31xDGXKLy5BXXIa8ioC1bs8rLpOWx+SXlCO/pBwXsh1so5cCwX6VE5aC/Sx/hviqEOKnQbi/5SvIV83eKhE1CIOSnEqtVECvU0Cvq195vjKTuUpwVvZQsyt6plcLjbhaVGp5XfF9SZkZxWUmpGYXIzW72O75lXIZQv3UCPPXINzfG2H+GkS08Ub7QC3aB2oRGejN3ikR1Yi/GahF8FLILT1CX7XDxxSVliOzoLRiwlIpMguNyKp4nVlxXzUtrwQZBSUoNwtczivB5bwSALk1ni/YV432gZXhGR3sgy6hfugc6gtvlcI5PygRuR0GJbktH7USPmolooN97O5XbjIjq9CIK3nFSMsrQVp+Ca7kleBSTjEuZBuQmmNArqFMCtzkC7k2x8tkQLsAb3QN9UNnvS+6hPqha8WfDFAiz8egJI+nVNQ9kSmvuAyp2QakZhtwIduA89kGnMksxMn0QlwtMkrDu1uOZVSeVy5DzwgdBrYPQExUAAZGBSDCX8OlMUQehusoiepwtbAUJzMKcTK9ACczCnEivUAK0GuF6TSIiQrAgPZtEBMVgF4R/lAp+dhXopaIBQdqwaAkZxBC4FJuMQ6cz8HBC7k4cD4Hf17Jh8ls+7+TSilH37b+GBgVgIHtAzAwqg2fQ0rUQrhNUC5ZsgSvvfYa0tLS0K9fP7zzzjsYPHhwrfvn5uZi3rx5+Oabb5CdnY2oqCgsXrwYd955p0Ofx6CkpmIwluNQah6SL+TgwPkcJF/IQW4N5QXbBXgjJioA10UH4pauIYgM1LqgtUTkFpV5Vq9ejdmzZ2PZsmWIjY3F4sWLkZCQgOPHjyM0NLTa/kajEbfddhtCQ0OxZs0atG3bFufPn0ebNm2av/FE19CqlIjrFIS4TkEALL3Os1lFSK7ocR68kIPj6QW4mFOMiznF+C7lMgCgY4gPbu4Sglu6heD6DkGcIETUwri0RxkbG4vrrrsO7777LgDAbDYjMjISM2bMwLPPPltt/2XLluG1117DsWPH4OXVsMdKsUdJrlRQUoZDqXk4cD4Hu05n4cD5HJvhWpVSjtgOlp5mXKcgdNX7wUvBe5xETaHFD70ajUZotVqsWbMGo0aNkraPHz8eubm5+O6776odc+eddyIwMBBarRbfffcdQkJCMHbsWMyZMwcKRc3/Ci8tLUVpaWWd0vz8fERGRjIoqUXILynD7lNXsf1EJn45kYlLubaFE1RKOXqE+aFXW3/0aeuP3hH+6BrmC7WSvU6ixmrxQ69ZWVkwmUzQ6/U22/V6PY4dO1bjMWfOnMH//vc/PPTQQ1i/fj1OnTqFJ554AmVlZUhMTKzxmKSkJCxatMjp7SdyBp3GCyN6h2FE7zAIIXA6sxDbjmdi+4lMpKTmoqCkHIcu5uHQxTzpGC+FDF31fhjQvg1u6RqKuE5B8FVzpRdRU3FZj/Ly5cto27Ytdu/ejbi4OGn7P//5T2zfvh2//fZbtWO6du2KkpISnD17VupBvvnmm3jttddw5cqVGj+HPUpyV2azQGqOAYcv5eHIpXwcuZSHI5fzqk0Q8lLIEBMVgFu6huKWriHoEe7HtZxEDmjxPcrg4GAoFAqkp6fbbE9PT0dYWFiNx4SHh8PLy8tmmLVHjx5IS0uD0WiESqWqdoxarYZa7XhZNKKWQi6XISrIB1FBPri7bwQAywShiznFOHIpD3vOWIZsz1814Ncz2fj1TDZe2XAMoX5q3Nw1BCP7ReCWriEu/imI3J/LglKlUiEmJgZbtmyR7lGazWZs2bIF06dPr/GYIUOGYOXKlTCbzZDLLRMcTpw4gfDw8BpDksjTyGQyRAZqERmoxR19wgEA57KK8MvJTGw/nondp68io6AUaw5cxJoDFzE2tj0W3N0TGi/e0yRqKJfOel29ejXGjx+P999/H4MHD8bixYvx5Zdf4tixY9Dr9Rg3bhzatm2LpKQkAEBqaip69eqF8ePHY8aMGTh58iQmTpyIJ598EvPmzXPoMznrlTxZabkJ+8/lYP3hK1i59wKEALqH+eHdsQPROdTX1c0jalFa/NArADz44IPIzMzEggULkJaWhv79+2PDhg3SBJ8LFy5IPUcAiIyMxMaNGzFr1iz07dsXbdu2xVNPPYU5c+a46kcgalHUSgWGdA7GkM7BGNE7DLNWp+BYWgFGvrMTL4zqjXtj2rm6iURux+WVeZobe5TUmmQUlGDmqhTsPn0VAHBfTDs895deLf7ZmyVlJpSbBWfzUpNyNA+4kpnIg4X6afB/k2Lx9G1dIZcBaw5cxMh3duJYWr6rm1YrIQT+8u4uDH1tK0rKTK5uDhGDksjTKeQyzBjeBSsnXw+9To3TmUX4y7u78OW+VFc3rUb5xeU4nl6ArEIj0vJKXN0cIgYlUWtxfccgrH/yJgztFoLScjP++fXv+C7lkqubVc3lvMrqRHnF1YvKEzU3BiVRKxLkq8ZH46/DpBs7AAD+8dXvOHA+28WtsnWFQUktDIOSqJWRy2WYd2cPJPTSw2gyY8pnB5CabXB1sySXcyuHW/NLGJTkeg0Kys8++8ymLJyV0WjEZ5991uhGEVHTkstleOvB/ujdVoerRUZM/GRfiwkl9iippWlQUE6YMAF5eXnVthcUFGDChAmNbhQRNT2tSokPx1+HMJ0GJzMKMe3zZJSbzK5uFq5U6VEyKKklaFBQCiFqLLp88eJF+Pv7N7pRRNQ89DoNPhg/CN5eCuw4mYXE7/+Aq5dWV53Mk19c7sKWEFnUazXvgAEDIJPJIJPJMHz4cCiVlYebTCacPXsWI0aMcHojiajp9G7rj7fHDMCU/9uPz3+7gI4hvtJkH1e4ksceJbUs9QpKa/HylJQUJCQkwNe3snakSqVCdHQ07r33Xqc2kIia3m099fjXHT3w4vqjeGHdn4gO0mJ4D33dBzqZEMImKPMZlNQC1CsorQ9Hjo6Oxt/+9jc+vorIgzx2UwecySrEF3tTMeOLg1gz9Qb0jGjeMo9Xi4wwllfeJ20pE4yodWvQPcphw4YhMzNTer13717MnDkTy5cvd1rDiKh5yWQyPPeX3rihUxAMRhMmf7YfxcbmLSFXdSIPwKFXahkaFJRjx47F1q1bAQBpaWmIj4/H3r17MW/ePDz33HNObSARNR8vhRxLH4pB2zbeuJRbjC/3N2+ZO+tEHnnFXEEOvVJL0KCgPHLkCAYPHgwA+PLLL9GnTx/s3r0bn3/+OT755BNnto+Impm/1gtTb+kIAFj+yxmUNeOSkSu5lqDsEOwDgD1KahkaFJRlZWXS/cmff/4Z99xzDwCge/fuuHLlivNaR0Qucf+gSAT7qnAptxjfp1xuts+1TuTpHma5N5pfUu7y5SpEDQrKXr16YdmyZdixYwc2b94sLQm5fPkygoKCnNpAImp+Gi8FJlYsEVm2/TTM5uYJq8tSUPoBAExmgaJmvk9KdK0GBeUrr7yC999/H0OHDsWYMWPQr18/AMD3338vDckSkXt7+Poo+KmVOJlRiJ+PpjfLZ0pDryE+UCksv544/Equ1qDHhw8dOhRZWVnIz89HQECAtH3KlCnQarVOaxwRuY5O44WH46KwdNtpvLftNG7rqa+xIpczWYdew/29ofP2QlZhKfIMZWjbxrtJP5fIngY/PUShUKC8vBw7d+7Ezp07kZmZiejoaISGhjqzfUTkQhOGREOllCMlNRe/nmnax3GZzAJp+ZagjGijgc7b8u94rqUkV2tQUBYVFWHixIkIDw/HzTffjJtvvhkRERGYNGkSDIaW87geImqcUD8NHhjUDgDw3rZTTfpZmQWlMJkFFHIZQv008Pf2AsChV3K9BgXl7NmzsX37dvzwww/Izc1Fbm4uvvvuO2zfvh1PP/20s9tIRC7095s7QSGXYcfJLBy5VP2pQc5iXUMZptNAIZcxKKnFaFBQfv311/jwww9xxx13QKfTQafT4c4778SKFSuwZs0aZ7eRiFwoMlCLu/uGAwCWbjvdZJ9jrcoT7q8BYLlHCrDoALleg4LSYDBAr69eMDk0NJRDr0Qe6PGhnQAA649cwZnMwib5DOsDm8MrJu5Ye5QMSnK1BgVlXFwcEhMTUVJSWZexuLgYixYtQlxcnNMaR0QtQ/cwHYZ3D4UQlmo9TeFyRY8yoqJHKQVlCZ9JSa7VoOUhixcvxogRI9CuXTtpDeWhQ4egVquxadMmpzaQiFqGx4d2wpZjGfg6+SJmxndFWEWgOYvUo7QOvVbMeuU9SnK1BvUo+/Tpg5MnTyIpKQn9+/dH//798fLLL+PUqVPo1auXs9tIRC3AoOhADI4ORJlJ4IMdzu9VWqvyXDv0yqAkV2tQjzIpKQl6vR6TJ0+22f7RRx8hMzMTc+bMcUrjiKhlefzWTtj7cTZW7r2A6cM6o41W5bRzW6vyRPhbgpKTeailaFCP8v3330f37t2rbbfWgCUizzS0awh6hOtgMJrw6e7zTjuvsdyMzMJSAEB4G9t7lOxRkqs1KCjT0tIQHh5ebXtISAifHkLkwWQymTQD9pPdZ1Fa7pyC5en5JRACUCnlCPKx9FJ1DEpqIRoUlJGRkdi1a1e17bt27UJERESjG0VELdedvcMQ4qdGjqEMB87lOOWcl3MrJ/JY68lWznplUJJrNege5eTJkzFz5kyUlZVh2LBhAIAtW7bgn//8JyvzEHk4pUKOmzoH45uDl7DjVBZu6Bzc6HNWFkOvnElr7VGWlJlRWm6CWqlo9OcQNUSDgvIf//gHrl69iieeeAJGoxEAoNFoMGfOHMydO9epDSSilufGLpag3HkyC3NGNP581vJ11ok8AOCnVkImA4SwDL+G+jEoyTUaFJQymQyvvPIK5s+fj6NHj8Lb2xtdunSBWq12dvuIqAW6saIXeeRyHnKKjAjwadzsV6l8XZvKHqVcLoOfWon8knLkF5cj1K9RH0HUYA1+zBYA+Pr64rrrrkPv3r0ZkkStSKhOg256PwgB7Dqd1ejzVRYbsH3upL+WE3rI9RoVlETUet3YxdKr3Hmy8UEpla9rY1vth/VeqSVgUBJRg1iDcsfJLAghGnWu2nqUUtEBJ898fW3jMcxcdbDR7abWgUFJRA0S2yEQKoUcl3KLcTarqMHnKTaakGOwBGHEtUOvTbCW0mwWWLb9DL5NuYwzjWg3tR4MSiJqEK1KiYFRbQAAO081fPjV2pvUqhRSIXSrphh6zS8pg8ls6Umm55fUsTcRg5KIGuGmLiEALMOvDVV1DaW12IBVU1TnuVpklL7PLCh12nnJczEoiajBrMtEfj19FeUmc4POYa3KE9HGu9p7TTH0mlMlKNmjJEcwKImowXq39Ye/txcKSstx6GJug85h7VFee38SAHQay1BsfrHzHt6cXSUoM/LZo6S6MSiJqMEUchmGdA4C0PDhV2nGa5vqD4JuiqHXHEOVHiWHXskBDEoiapQbO1vuUzZ0PaW0hrKGHmVTDL1mF1Wei0Ov5AgGJRE1yk0V6ykPpuaioAHrHR3pUTpzHWXVHiUn85AjGJRE1CiRgVpEBWlhMgv8eia73sdLdV6brUfJyTxUPwxKImo06+zXnScz63VcQUkZCkotE3WuLV8HVAZlQUm5tPaxsarOejUYTSgsdd5EIfJMLSIolyxZgujoaGg0GsTGxmLv3r0OHbdq1SrIZDKMGjWqaRtIRHZZh1931LPwgHXGq7+3F7Sq6g8zspawA4DCEucEWnaVoVeAvUqqm8uDcvXq1Zg9ezYSExORnJyMfv36ISEhARkZGXaPO3fuHJ555hncdNNNzdRSIqpNXKdgyGXAmcwiaV2kI6z7Vn1gc1UqpRzeXpbnUDpr+LXq0CvAoKS6uTwo33zzTUyePBkTJkxAz549sWzZMmi1Wnz00Ue1HmMymfDQQw9h0aJF6Nixo93zl5aWIj8/3+aLiJzL39sL/SLbAKjf7FdpDWUNxQaqnhtw3oQea1CG+lkeDcgJPVQXlwal0WjEgQMHEB8fL22Ty+WIj4/Hnj17aj3uueeeQ2hoKCZNmlTnZyQlJcHf31/6ioyMdErbicjWTZ3rP/x6pY4eJQCp/qszepRlJjMKKoZwu4frALBHSXVzaVBmZWXBZDJBr9fbbNfr9UhLS6vxmJ07d+LDDz/EihUrHPqMuXPnIi8vT/pKTU1tdLuJqLobK+q+7jqVBbODE28u16NH6YygtC4NkcmArqG+AFidh+pW/e55C1ZQUIBHHnkEK1asQHBwsEPHqNVqqNXqJm4ZEQ1o3wY+KgWyi4z480o+erf1r/OYyudQ2ulRapz3BJGcimIDAVoVwio+k9V5qC4uDcrg4GAoFAqkp6fbbE9PT0dYWFi1/U+fPo1z585h5MiR0jaz2VKIWalU4vjx4+jUqVPTNpqIauSlkOP6jkHYciwDO09lORaUdtZQWjmzR2m9Pxmg9YJeVxGUHHqlOrh06FWlUiEmJgZbtmyRtpnNZmzZsgVxcXHV9u/evTsOHz6MlJQU6euee+7BrbfeipSUFN5/JHKxG63LRBxYTymEwOU865ND7N2jdP7Qa6CPipN5yGEuH3qdPXs2xo8fj0GDBmHw4MFYvHgxioqKMGHCBADAuHHj0LZtWyQlJUGj0aB37942x7dp0wYAqm0nouZnXU+571wOSspM0FQs7ahJrqEMJWWWEaEwu5N5nDfrtbJHqWKPkhzm8qB88MEHkZmZiQULFiAtLQ39+/fHhg0bpAk+Fy5cgFzu8lUsROSATiG+CNNpkJZfgr1ns3Fz15Ba97X2JoN9VVAraw/UyqHXxhccsFblCfRRIVRn6VFaq/P4ql3+65BaqBbxN2P69OmYPn16je9t27bN7rGffPKJ8xtERA0ik8lwY5dgrDlwETtPZdkNSkfuTwJOvkdZMfQa4KOCVqWEn1qJgtJypOeXwDfEt9HnJ8/ErhoROZVUzq6OwgOOzHgFqj682XlDr4FaFQBIvUoOv5I9DEoicqohFYUHjl7Jx5FLebXudym37jWUQJXKPM6c9epTEZR+lpDmhB6yh0FJRE4V7KvG3X3DAQDz1h6u9akfVxyY8QoA/lrnTeapnPVqOaeePUpyAIOSiJxuwd094adR4tDFPPzfnnM17uPoPUprwYG84jII0bhHbVkLDgT6WAIytGLmK6vzkD0MSiJyulCdBnNGdAcAvL7phNR7rMqRNZRA5dBrmUmguMzUqHZVu0dZsZaS1XnIHgYlETWJsYPbY0D7NigsLcfC7/+wec9sFtJwZ109Sq1KAYVcBgDIb8QSkWKjSQraAGno1dqj5NAr1Y5BSURNQi6XIemvfaCUy7Dxj3Rs+qPyQQdZhaUoMwnIZZW9utrIZDKnLBGx3p/0UsikNZPWz85gj5LsYFASUZPpHqbDYzdZnhmb+P0fKCy19AitTw3R6zRQKur+NeSMoKxalUcmk0mfD3AyD9nHoCSiJvXU8C6IDPTGlbwSvLnpBADHnkNZlTPWUlat82p1bXUeopowKImoSXmrFHj+L5ZazJ/sPovDF/OkHmV4HWsorZxRGL1qj9LKWp0HYK+SasegJKImN7RbKEb2i4BZAHPX/o6LOQYAQISDPUpnDr1W7VECQEhFr5JLRKg2DEoiahbz7+4BnUaJI5fysXpfKoC6Z7xaOeMJIjlSVR4vm+36iuo8GQXsUVLNGJRE1CxC/TR49o4eACz3BIG611BaOaVHabBdQ2nF6jxUFwYlETWbv10XiZioAOm1oz3KynqvDZ9wU1mVxzYoWZ2H6sKgJKJmI5fL8NJoy9pKpVyG9oFah46rWsauoa4tiG7F6jxUlxbxPEoiaj26hflh1ZTrUVxmqhZatXHGE0RqWh4CVO1RcuiVasagJKJmNyg6sF77+zthMk9Ny0MAQM/qPFQHDr0SUYun87b8m76hQ69CiFp7lKzOQ3VhUBJRi9fYWa8FpeUoM1ke0XVtj5LVeaguDEoiavGsk3kMRhPKTOZ6H29dQ+ntpYC3SmHzHqvzUF0YlETU4lkLDgANm9BTW1UeK1bnIXsYlETU4inkMqnX15DhV+v9yWur8lixOg/Zw6AkIrdQWcau/vcRs6ViAzU/+zKU1XnIDgYlEbmFxjxBxHqPMlBbS4+S1XnIDgYlEbkFf++GP5My21BzVR4rVuchexiUROQWGlPGrrJHWUtQsjoP2cGgJCK30Ji1lLXVebVidR6yh0FJRG6hMWXsaqvKY8UeJdnDoCQit6BrRGH0q7XUebWy3qMsYnUeqgGDkojcQmOGXnPqKDjgo2Z1Hqodg5KI3IJOmvVavx6fySyQWxGutRUcAFidh2rHoCQit9DQHmVecRmEpR56rUOvAKvzUO0YlETkFhoalNYZrzqNEl6K2n/lhbJHSbVgUBKRW7Cuo6zvrNe6Zrxa8bmUVBsGJRG5Bf8qs17NZuHwcXWtobRidR6qDYOSiNyCdXmIWQBFRscn9NRVlceKaympNgxKInILGi8FVErLr6z63Kesq86rFavzUG0YlETkNhoyoSe70LF7lOxRUm0YlETkNirvUzo+9Cr1KOsaeq1HdZ7dp7Pw4++XHW4DuTelqxtAROQoncbyK6s+PcrKqjy1FxsALNV5fNVKFJaWIz2/BL4hvrWeb8LH+1Babkaftv6ICvJxuC3kntijJCK34d+Aeq/ZhoqqPHX0KAHH1lJ+nXwRpeVmAMAfl/Mdbge5LwYlEbkNXQOeIGLtUQb51h2UdVXnEUJg5W8XpNfH0gocbge5LwYlEbmNhkzmyanjySFV1dWj3HPmKs5kFUmvj6exR9kaMCiJyG3UNyiN5WYUVEzMqWvWK1B3dZ7PK3qTnUMt9y+Ps0fZKjAoichtSGXsHAzK3IoZr3JZ5bH22KvOk1lQio1H0gAA8+/uCQA4n22AoR7FD8g9tYigXLJkCaKjo6HRaBAbG4u9e/fWuu+KFStw0003ISAgAAEBAYiPj7e7PxF5jvr2KKsuDZHLZXXub28t5VcHUlFuFugf2QY3dwlGoI8KQgAn0wsdbT65KZcH5erVqzF79mwkJiYiOTkZ/fr1Q0JCAjIyMmrcf9u2bRgzZgy2bt2KPXv2IDIyErfffjsuXbrUzC0nouamq29QFjpWlceqtuo8ZrPAF3stw64PxbaHTCZD9zA/ABx+bQ1cHpRvvvkmJk+ejAkTJqBnz55YtmwZtFotPvrooxr3//zzz/HEE0+gf//+6N69Oz744AOYzWZs2bKlmVtORM1NenhziWPDndYeZV11Xq1q61HuOJWF1Oxi+GmUuLtvBACgW0VQcuar53NpUBqNRhw4cADx8fHSNrlcjvj4eOzZs8ehcxgMBpSVlSEwMLDG90tLS5Gfn2/zRUTuqb5Dr9KM1zqKDVjVVp3n81/PAwDuHdgO3ioFAFT2KNP5O8XTuTQos7KyYDKZoNfrbbbr9XqkpaU5dI45c+YgIiLCJmyrSkpKgr+/v/QVGRnZ6HYTkWvUt+BAdpFlP0dmvAKV1XmAyl5lWl4Jthyz3Ap6KLa9tG+3MB0ADr22Bi4fem2Ml19+GatWrcLatWuh0Whq3Gfu3LnIy8uTvlJTU5u5lUTkLNZ7lKXlZpSUmerc39GHNldlXUuZXrGWcvW+VJjMAoOjA9FF7yft11XvC5kMyCo0IquQTxzxZC4NyuDgYCgUCqSnp9tsT09PR1hYmN1jX3/9dbz88svYtGkT+vbtW+t+arUaOp3O5ouI3JOvSgnr5FVHepXZ9Sg2YBUqTegpQbnJjFX7LJN4xlbpTQKAVqVE+0AtAPYqPZ1Lg1KlUiEmJsZmIo51Yk5cXFytx7366qt4/vnnsWHDBgwaNKg5mkpELYBcLqtXGbuG9Cj10oSeUmw7nokreSUI0HphRO/q/3jvpueEntbA5UOvs2fPxooVK/Dpp5/i6NGjePzxx1FUVIQJEyYAAMaNG4e5c+dK+7/yyiuYP38+PvroI0RHRyMtLQ1paWkoLORaJqLWwFo4wJEJPVKPsgFBmZ5fgpUVS0Lui2kHjZei2r6VS0Q4oceTufwxWw8++CAyMzOxYMECpKWloX///tiwYYM0wefChQuQyyvzfOnSpTAajbjvvvtszpOYmIiFCxc2Z9OJyAXqM/NVesRWA4ZeD6bmIvlCDgBgzOD2Ne7LCT2tg8uDEgCmT5+O6dOn1/jetm3bbF6fO3eu6RtERC2WtJbSgYc3ZzdoMo+lR3ngvCUkb+gUhI61PJvSupbyRHohzGbhUPUfcj8uH3olIqoPR3uUBmM5Ssosz42sz9CrtUdp9VBsVK37RgdpoVLKUVxmwoVsg8OfQe6FQUlEbsXRoLTen1Qp5PBRVb+/WBvrPUoACPZV4bae+lr3VSrk6FLxJBFO6PFcDEoiciuOPkEkp6LYQICPF2Qyx4dEq/YoHxgUCZXS/q/Jbqz56vEYlETkVhwtjF55f1Jtd79r+aiV6BDsA42XvNZJPFWxlJ3naxGTeYiIHOXv4DpKacarg3Veq1o15XoYjCZEVhQUsMc685VDr56LQUlEbsXhHmUDqvJYVb1PWRdrj/JcVhFKykw1rrck98ahVyJyK5WTeewvD2lIVZ6GCPVTo43WC2YBnMpg4RNPxKAkIrfi6BNEGtOjrA+ZTMZSdh6OQUlEbkWnsRYcqOMeZTP1KAGWsvN0DEoicivWHmVBaTlMZlHrflcL61/ntaE4ocezMSiJyK1YJ/MAlb3Gmkg9yiYeegW4ltLTMSiJyK14KeToGOIDAPi/Pedr3S+7SsGBpmYNyoyCUmlZCnkOBiURuZ1nbu8GAHj/l9O4nFtc7X0hRLPeo/RVK9EuwBsAh189EYOSiNzOHb3DMDg6ECVlZry64Vi19/NLKu9fNvWsVytO6PFcDEoicjsymQzz7+4JmQz4NuUyDlY8N9LKOvzpo1I0WwEA6T5lOnuUnoZBSURuqU87f9w7sB0A4Lkf/4QQlTNgrXVem2PGqxVnvnouBiURua1/JHSDVqXAwQu5+P7QZWl7ZZ3X5gtK69DribQCmO0sWyH3w6AkIrel12nw+C2dAACv/HQMJWUmAM1XlaeqDsE+8FLIUGQ04VINE4zIfTEoicitTb65IyL8NbicV4IVv5wBUBmUzdmj9FLI0SmED3H2RAxKInJrGi8Fnr2zBwDgvW2nkZ5fUnmPshl7lABnvnoqBiURub2RfcMxsH0bFJeZ8NrG4416FmVjcEKPZ2JQEpHbsy4XAYA1By7it7PZAJp31itQtUfJoPQkDEoi8ggD2gdg9IC2AIDzVw0AgKBmDkrrWsozWUUoLTc162dT02FQEpHH+OeIbtB4Vf5aa+57lOH+GvhplDCZBU5nFDXrZ1PTYVASkccI9/fG32/uJL1uzlmvgGUIWBp+TeeEHk/BoCQij/L3WzqiY4gPgn1VaBegbfbPtw6/ckKP51C6ugFERM6kVSnx44wbAQDequap81qVdeYrJ/R4DgYlEXkcrcp1v9o489XzcOiViMiJuuotQXklrwS7T2e5uDXkDAxKIiIn8vf2wo2dgwEAD3/wG/7z80np2ZjknhiUREROtnxcDO6LaQezAN76+QQe+fA3ZBSUuLpZ1EAMSiIiJ9OqlHj9/n544/5+0KoU2H36Ku78zw7sOJnp6qZRAzAoiYiayL0x7fD99BvRPcwPWYVGjPtoL17feBzlJrOrm0b1wKAkImpCnUN98e20IRgb2x5CAO9uPYUxK37FlTw+s9JdyIQQreouc35+Pvz9/ZGXlwedTufq5hBRK/LDocuY+81hFJaWw9tLgYReevylf1vc2CUYXgr2W5qbo3nAoCQiakbnsorw1KqDOHQxT9oW6KPCXX3CMWpABAa2D4BMJnNhC1sPBmUtGJRE5GpCCKSk5uK7lMv48ffLyCo0Su+1C/DGX/pH4I7e4ege5gcle5pNhkFZCwYlEbUk5SYzdp2+iu9SLmHjkTQUGSsfz+XtpUDvtjr0a9cG/SLboH9kG7QL8GaP00kYlLVgUBJRS1VsNGHLsXR8l3IZv56+ioLS8mr7BPqo0K+dP3pF+CM62AfRQVpEBVmKwDNA64dBWQsGJRG5A7NZ4ExWEQ6l5uLQxVwcSs3Fn1fyUWaq+Ve2j0qBqCAfdAj2QVSQFpGBWuh1auh1Guh1GgRqVZDLGaRVMShrwaAkIndVWm7C0SsFSLmQgxMZhTh/tQjnsgy4nFeMun6TeylkCPXTIFSnhr7izwCtCoE+KgT4qBCoVSHAx8vyWquCxqv5n7zS3BzNAz49hIjITaiVCvSvuFdZVWm5CanZxZbgvGrAuawiXM4tRlp+CdLzS3G1qBRlJoFLucW4lOvY+k2Nlxx+Gi/oNEr4abzgp1FC513ltVoJrVoJX7UCWpUSPhV/+qqV0Kos33t7KaBRyaFSyN16WJhBSUTk5tRKBTqH+qJzqG+N75eZzMgsKEVafgky8kuQlleCzMJS5BjKkGswIrvIiJyiMmQbjMgpMqLcLFBSZkZJWSkyC0ob3T65DNB4KSzB6aWAt0oBjZccamXtf6qVcqiVcqisXwo5VEoFVFW2x3YIRButqtHtqwuDkojIw3kp5Iho442INt517iuEQEFpOfIMZcgvKUNBSTnyiyv+rPK6sLQcRUYTDKXlKDKWo6jUhCJjOQzWP40m6akpZgEYjCYYqszodYZvpw1BfwYlERE1J5lMBp3GCzqNV6PPVWYyo7jMhBKjCSVllu+Ly0woNppQUm5CaZkJpeVmlJaZK16bUVKxraTMBKPJDGO55avUZNnPss0EY7kZOk3zRBiDkoiImoSXQg4vhdwpoetKLaLkw5IlSxAdHQ2NRoPY2Fjs3bvX7v5fffUVunfvDo1Ggz59+mD9+vXN1FIiImptXB6Uq1evxuzZs5GYmIjk5GT069cPCQkJyMjIqHH/3bt3Y8yYMZg0aRIOHjyIUaNGYdSoUThy5Egzt5yIiFoDl6+jjI2NxXXXXYd3330XAGA2mxEZGYkZM2bg2Wefrbb/gw8+iKKiIvz444/Stuuvvx79+/fHsmXL6vw8rqMkIiLA8TxwaY/SaDTiwIEDiI+Pl7bJ5XLEx8djz549NR6zZ88em/0BICEhodb9S0tLkZ+fb/NFRETkKJcGZVZWFkwmE/R6vc12vV6PtLS0Go9JS0ur1/5JSUnw9/eXviIjI53TeCIiahVcfo+yqc2dOxd5eXnSV2pqqqubREREbsSly0OCg4OhUCiQnp5usz09PR1hYWE1HhMWFlav/dVqNdRqtXMaTERErY5Le5QqlQoxMTHYsmWLtM1sNmPLli2Ii4ur8Zi4uDib/QFg8+bNte5PRETUGC4vODB79myMHz8egwYNwuDBg7F48WIUFRVhwoQJAIBx48ahbdu2SEpKAgA89dRTuOWWW/DGG2/grrvuwqpVq7B//34sX77clT8GERF5KJcH5YMPPojMzEwsWLAAaWlp6N+/PzZs2CBN2Llw4QLk8sqO7w033ICVK1fi3//+N/71r3+hS5cu+Pbbb9G7d29X/QhEROTBXL6OsrlxHSUREQF8HmWtrP8u4HpKIqLWzZoDdfUXW11QFhQUAADXUxIREQBLLvj7+9f6fqsbejWbzbh8+TL8/Pwa9cTt/Px8REZGIjU1lUO4DcDr1zi8fo3D69c4nnL9hBAoKChARESEzVyYa7W6HqVcLke7du2cdj6dTufWf1FcjdevcXj9GofXr3E84frZ60laeXxlHiIiosZgUBIREdnBoGwgtVqNxMRElsdrIF6/xuH1axxev8Zpbdev1U3mISIiqg/2KImIiOxgUBIREdnBoCQiIrKDQUlERGQHg7IBlixZgujoaGg0GsTGxmLv3r2ublKL9csvv2DkyJGIiIiATCbDt99+a/O+EAILFixAeHg4vL29ER8fj5MnT7qmsS1MUlISrrvuOvj5+SE0NBSjRo3C8ePHbfYpKSnBtGnTEBQUBF9fX9x7773VHmzeWi1duhR9+/aVFsXHxcXhp59+kt7ntaufl19+GTKZDDNnzpS2tZZryKCsp9WrV2P27NlITExEcnIy+vXrh4SEBGRkZLi6aS1SUVER+vXrhyVLltT4/quvvoq3334by5Ytw2+//QYfHx8kJCSgpKSkmVva8mzfvh3Tpk3Dr7/+is2bN6OsrAy33347ioqKpH1mzZqFH374AV999RW2b9+Oy5cv469//asLW91ytGvXDi+//DIOHDiA/fv3Y9iwYfjLX/6CP/74AwCvXX3s27cP77//Pvr27WuzvdVcQ0H1MnjwYDFt2jTptclkEhERESIpKcmFrXIPAMTatWul12azWYSFhYnXXntN2pabmyvUarX44osvXNDCli0jI0MAENu3bxdCWK6Vl5eX+Oqrr6R9jh49KgCIPXv2uKqZLVpAQID44IMPeO3qoaCgQHTp0kVs3rxZ3HLLLeKpp54SQrSuv3/sUdaD0WjEgQMHEB8fL22Ty+WIj4/Hnj17XNgy93T27FmkpaXZXE9/f3/ExsbyetYgLy8PABAYGAgAOHDgAMrKymyuX/fu3dG+fXtev2uYTCasWrUKRUVFiIuL47Wrh2nTpuGuu+6yuVZA6/r71+qKojdGVlYWTCYT9Hq9zXa9Xo9jx465qFXuKy0tDQBqvJ7W98jCbDZj5syZGDJkCHr37g3Acv1UKhXatGljsy+vX6XDhw8jLi4OJSUl8PX1xdq1a9GzZ0+kpKTw2jlg1apVSE5Oxr59+6q915r+/jEoidzAtGnTcOTIEezcudPVTXEr3bp1Q0pKCvLy8rBmzRqMHz8e27dvd3Wz3EJqaiqeeuopbN68GRqNxtXNcSkOvdZDcHAwFApFtVld6enpCAsLc1Gr3Jf1mvF62jd9+nT8+OOP2Lp1q80j4sLCwmA0GpGbm2uzP69fJZVKhc6dOyMmJgZJSUno168f/vOf//DaOeDAgQPIyMjAwIEDoVQqoVQqsX37drz99ttQKpXQ6/Wt5hoyKOtBpVIhJiYGW7ZskbaZzWZs2bIFcXFxLmyZe+rQoQPCwsJsrmd+fj5+++03Xk9Yls5Mnz4da9euxf/+9z906NDB5v2YmBh4eXnZXL/jx4/jwoULvH61MJvNKC0t5bVzwPDhw3H48GGkpKRIX4MGDcJDDz0kfd9ariGHXutp9uzZGD9+PAYNGoTBgwdj8eLFKCoqwoQJE1zdtBapsLAQp06dkl6fPXsWKSkpCAwMRPv27TFz5ky88MIL6NKlCzp06ID58+cjIiICo0aNcl2jW4hp06Zh5cqV+O677+Dn5yfd9/H394e3tzf8/f0xadIkzJ49G4GBgdDpdJgxYwbi4uJw/fXXu7j1rjd37lzccccdaN++PQoKCrBy5Ups27YNGzdu5LVzgJ+fn3Q/3MrHxwdBQUHS9lZzDV097dYdvfPOO6J9+/ZCpVKJwYMHi19//dXVTWqxtm7dKgBU+xo/frwQwrJEZP78+UKv1wu1Wi2GDx8ujh8/7tpGtxA1XTcA4uOPP5b2KS4uFk888YQICAgQWq1WjB49Wly5csV1jW5BJk6cKKKiooRKpRIhISFi+PDhYtOmTdL7vHb1V3V5iBCt5xryMVtERER28B4lERGRHQxKIiIiOxiUREREdjAoiYiI7GBQEhER2cGgJCIisoNBSUREZAeDkoiIyA4GJbV4Q4cOxcyZM13djGpkMhm+/fZbVzcDjzzyCF566SWXfPYnn3xS7TFLzeXcuXOQyWRISUlx+rm3bdsGmUxWreB3Tf7880+0a9cORUVFTm8HtQwMSmrxvvnmGzz//PPS6+joaCxevLjZPn/hwoXo379/te1XrlzBHXfc0WztqMmhQ4ewfv16PPnkky5tR2vWs2dPXH/99XjzzTdd3RRqIgxKavECAwPh5+fn9PMajcZGHR8WFga1Wu2k1jTMO++8g/vvvx++vr5N+jmNvVauIIRAeXl5s3zWhAkTsHTp0mb7PGpeDEpq8aoOvQ4dOhTnz5/HrFmzIJPJIJPJpP127tyJm266Cd7e3oiMjMSTTz5pMxwWHR2N559/HuPGjYNOp8OUKVMAAHPmzEHXrl2h1WrRsWNHzJ8/H2VlZQAsQ4uLFi3CoUOHpM/75JNPAFQfej18+DCGDRsGb29vBAUFYcqUKSgsLJTef/TRRzFq1Ci8/vrrCA8PR1BQEKZNmyZ9FgC899576NKlCzQaDfR6Pe67775ar4vJZMKaNWswcuRIm+3Wn3PMmDHw8fFB27ZtsWTJEpt9cnNz8dhjjyEkJAQ6nQ7Dhg3DoUOHpPetvegPPvgAHTp0qPPBvRs3bkSPHj3g6+uLESNG4MqVK9J7NQ2djxo1Co8++qhNm1966SVMnDgRfn5+aN++PZYvX25zzN69ezFgwABoNBoMGjQIBw8etHnfOlz6008/ISYmBmq1Gjt37oTZbEZSUhI6dOgAb29v9OvXD2vWrLE5dv369ejatSu8vb1x66234ty5czbvnz9/HiNHjkRAQAB8fHzQq1cvrF+/Xnr/tttuQ3Z2Nh8K7alcXJSdqE5Vn1hw9epV0a5dO/Hcc8+JK1euSE8qOHXqlPDx8RFvvfWWOHHihNi1a5cYMGCAePTRR6XzREVFCZ1OJ15//XVx6tQpcerUKSGEEM8//7zYtWuXOHv2rPj++++FXq8Xr7zyihBCCIPBIJ5++mnRq1cv6fMMBoMQwvJ0j7Vr1wohhCgsLBTh4eHir3/9qzh8+LDYsmWL6NChg/SUFCGEGD9+vNDpdGLq1Kni6NGj4ocffhBarVYsX75cCCHEvn37hEKhECtXrhTnzp0TycnJ4j//+U+t1yU5OVkAEGlpaTbbo6KihJ+fn0hKShLHjx8Xb7/9tlAoFDZPzoiPjxcjR44U+/btEydOnBBPP/20CAoKElevXhVCCJGYmCh8fHzEiBEjRHJysjh06FCNbfj444+Fl5eXiI+PF/v27RMHDhwQPXr0EGPHjq3xv5/VX/7yF5trExUVJQIDA8WSJUvEyZMnRVJSkpDL5eLYsWNCCCEKCgpESEiIGDt2rDhy5Ij44YcfRMeOHQUAcfDgQSFE5ZNq+vbtKzZt2iROnTolrl69Kl544QXRvXt3sWHDBnH69Gnx8ccfC7VaLbZt2yaEEOLChQtCrVaL2bNni2PHjon//ve/Qq/XCwAiJydHCCHEXXfdJW677Tbx+++/i9OnT4sffvhBbN++3eZnio2NFYmJibX+9yL3xaCkFu/aX7RRUVHirbfestln0qRJYsqUKTbbduzYIeRyuSguLpaOGzVqVJ2f99prr4mYmBjpdWJioujXr1+1/aoG5fLly0VAQIAoLCyU3l+3bp2Qy+VSkI0fP15ERUWJ8vJyaZ/7779fPPjgg0IIIb7++muh0+lEfn5+nW0UQoi1a9cKhUIhzGazzfaoqCgxYsQIm20PPviguOOOO4QQluui0+lESUmJzT6dOnUS77//vvQze3l5iYyMDLtt+PjjjwUA6R8dQgixZMkSodfrpdeOBuXDDz8svTabzSI0NFQsXbpUCCHE+++/L4KCgqT/lkIIsXTp0hqD8ttvv5X2KSkpEVqtVuzevdvm8ydNmiTGjBkjhBBi7ty5omfPnjbvz5kzxyYo+/TpIxYuXGj3WowePdrmH2bkOfjgZvIIhw4dwu+//47PP/9c2iaEgNlsxtmzZ9GjRw8AwKBBg6odu3r1arz99ts4ffo0CgsLUV5eDp1OV6/PP3r0KPr16wcfHx9p25AhQ2A2m3H8+HHo9XoAQK9evaBQKKR9wsPDcfjwYQCW4buoqCh07NgRI0aMwIgRIzB69GhotdoaP7O4uBhqtdpm+Nnq2ifMx8XFSROgDh06hMLCQgQFBVU73+nTp6XXUVFRCAkJqfNn12q16NSpk83PlJGRUedx1+rbt6/0vUwmQ1hYmHSeo0ePom/fvjZDwNf+jFZV/xufOnUKBoMBt912m80+RqMRAwYMkM4dGxtr8/61537yySfx+OOPY9OmTYiPj8e9995r014A8Pb2hsFgcPTHJTfCoCSPUFhYiL///e81zv5s37699H3VIAOAPXv24KGHHsKiRYuQkJAAf39/rFq1Cm+88UaTtNPLy8vmtUwmg9lsBmB5onxycjK2bduGTZs2YcGCBVi4cCH27dtX4xKM4OBgGAwGGI1GqFQqh9tQWFiI8PBwbNu2rdp7VT/n2mtVn59JVHnMrVwut3kNwOa+rL3zWK9NfVRtt/Ue8bp169C2bVub/eozEeuxxx5DQkIC1q1bh02bNiEpKQlvvPEGZsyYIe2TnZ1t8w8G8hyczENuR6VSwWQy2WwbOHAg/vzzT3Tu3Lnal70Q2b17N6KiojBv3jwMGjQIXbp0wfnz5+v8vGv16NEDhw4dspk8tGvXLsjlcnTr1s3hn02pVCI+Ph6vvvoqfv/9d5w7dw7/+9//atzXumTlzz//rPber7/+Wu21tVc9cOBApKWlQalUVrtWwcHBDrfVUSEhITaTe0wmE44cOVKvc/To0QO///47SkpKpG3X/ow16dmzJ9RqNS5cuFDtZ42MjJTOvXfvXpvjajp3ZGQkpk6dim+++QZPP/00VqxYYfP+kSNHpF4qeRYGJbmd6Oho/PLLL7h06RKysrIAWGau7t69G9OnT0dKSgpOnjyJ7777DtOnT7d7ri5duuDChQtYtWoVTp8+jbfffhtr166t9nlnz55FSkoKsrKyUFpaWu08Dz30EDQaDcaPH48jR45g69atmDFjBh555BFp2LUuP/74I95++22kpKTg/Pnz+Oyzz2A2m2sN2pCQEAwcOBA7d+6s9t6uXbvw6quv4sSJE1iyZAm++uorPPXUUwCA+Ph4xMXFYdSoUdi0aRPOnTuH3bt3Y968edi/f79Dba2PYcOGYd26dVi3bh2OHTuGxx9/3KGF/FWNHTsWMpkMkydPxp9//on169fj9ddfr/M4Pz8/PPPMM5g1axY+/fRTnD59GsnJyXjnnXfw6aefAgCmTp2KkydP4h//+AeOHz+OlStXSjObrWbOnImNGzfi7NmzSE5OxtatW6V/eACW4geXLl1CfHx8vX4ucg8MSnI7zz33HM6dO4dOnTpJ99D69u2L7du348SJE7jpppswYMAALFiwABEREXbPdc8992DWrFmYPn06+vfvj927d2P+/Pk2+9x7770YMWIEbr31VoSEhOCLL76odh6tVouNGzciOzsb1113He677z4MHz4c7777rsM/V5s2bfDNN99g2LBh6NGjB5YtW4YvvvgCvXr1qvWYxx57zOa+rNXTTz+N/fv3Y8CAAXjhhRfw5ptvIiEhAYBlSHP9+vW4+eabMWHCBHTt2hV/+9vfcP78eYdDvT4mTpyI8ePHY9y4cbjlllvQsWNH3HrrrfU6h6+vL3744QccPnwYAwYMwLx58/DKK684dOzzzz+P+fPnIykpCT169MCIESOwbt06dOjQAYBlaP7rr7/Gt99+i379+mHZsmXVKh2ZTCZMmzZNOr5r16547733pPe/+OIL3H777YiKiqrXz0XuQSauvXlARG6juLgY3bp1w+rVq6UJKNHR0Zg5c2aLLPvniYxGI7p06YKVK1diyJAhrm4ONQH2KIncmLe3Nz777DNpCJqa34ULF/Cvf/2LIenBOOuVyM0NHTrU1U1o1ayTg8hzceiViIjIDg69EhER2cGgJCIisoNBSUREZAeDkoiIyA4GJRERkR0MSiIiIjsYlERERHYwKImIiOz4f9WeLO4QkUJrAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train L-layer Model (with dropout)",
   "id": "988e7967aef48e2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:52:43.869472Z",
     "start_time": "2025-06-08T12:52:43.867673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.0075\n",
    "\n",
    "layers_config_dropout = [\n",
    "\t{\"dims\": 12288, \"keep_prob\": 1.0, \"activation\": None},\n",
    "\t{\"dims\": 20, \"keep_prob\": 0.935, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 7, \"keep_prob\": 0.97, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 5, \"keep_prob\": 1.0, \"activation\": \"relu\"},\n",
    "\t{\"dims\": 1, \"keep_prob\": 1.0, \"activation\": \"sigmoid\"},\n",
    "]"
   ],
   "id": "3d6522f3cc982d2d",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:45:10.497305Z",
     "start_time": "2025-06-08T12:45:10.495022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def L_layer_model_dropout(X, Y, layers, learning_rate = 0.0075, num_iterations = 3500, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    parameters = initialize_parameters_dropout(layers)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = forward_propagate_dropout(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = backward_propagate_dropout(AL, Y, parameters, caches)\n",
    "        parameters = update_parameters_dropout(parameters, grads, learning_rate)\n",
    "        if print_cost and (i % 100 == 0 or i == num_iterations - 1):\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    return parameters, costs"
   ],
   "id": "5e59dfdc08c6b530",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:53:06.515525Z",
     "start_time": "2025-06-08T12:52:45.401930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parameters_dropout, costs_dropout = L_layer_model_dropout(\n",
    "    train_x, train_y,\n",
    "    layers_config_dropout,\n",
    "    num_iterations = 4500,\n",
    "    print_cost = True)"
   ],
   "id": "aa81b270d7de26d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.0258749688787778\n",
      "Cost after iteration 100: 0.6779222796561502\n",
      "Cost after iteration 200: 0.664919524769807\n",
      "Cost after iteration 300: 0.6584582031724868\n",
      "Cost after iteration 400: 0.6526181547155522\n",
      "Cost after iteration 500: 0.6499885163628303\n",
      "Cost after iteration 600: 0.6468522405503876\n",
      "Cost after iteration 700: 0.6422966764509137\n",
      "Cost after iteration 800: 0.6429148047457786\n",
      "Cost after iteration 900: 0.6345804358770447\n",
      "Cost after iteration 1000: 0.6378479404947631\n",
      "Cost after iteration 1100: 0.633942208852748\n",
      "Cost after iteration 1200: 0.6293270129331571\n",
      "Cost after iteration 1300: 0.6269212444045841\n",
      "Cost after iteration 1400: 0.6269878443651782\n",
      "Cost after iteration 1500: 0.6188783933245767\n",
      "Cost after iteration 1600: 0.6146414743876418\n",
      "Cost after iteration 1700: 0.6187799769594197\n",
      "Cost after iteration 1800: 0.6073325456320547\n",
      "Cost after iteration 1900: 0.6040960069823471\n",
      "Cost after iteration 2000: 0.595795324271332\n",
      "Cost after iteration 2100: 0.6017471250269977\n",
      "Cost after iteration 2200: 0.5859261937923517\n",
      "Cost after iteration 2300: 0.5719346316936111\n",
      "Cost after iteration 2400: 0.5591430046385383\n",
      "Cost after iteration 2500: 0.5534965774680035\n",
      "Cost after iteration 2600: 0.5219440448458151\n",
      "Cost after iteration 2700: 0.49174355653350027\n",
      "Cost after iteration 2800: 0.4489237310690666\n",
      "Cost after iteration 2900: 0.4031441727704283\n",
      "Cost after iteration 3000: 0.4767606018630637\n",
      "Cost after iteration 3100: 0.3340939299885134\n",
      "Cost after iteration 3200: 0.20455429680350917\n",
      "Cost after iteration 3300: 0.22047413920309383\n",
      "Cost after iteration 3400: 0.23559031434733146\n",
      "Cost after iteration 3500: 0.22137835771908823\n",
      "Cost after iteration 3600: 0.16454473337717512\n",
      "Cost after iteration 3700: 0.18088921688504742\n",
      "Cost after iteration 3800: 0.13064966916046764\n",
      "Cost after iteration 3900: 0.16699437439357015\n",
      "Cost after iteration 4000: 0.13173638478666003\n",
      "Cost after iteration 4100: 0.137881102209312\n",
      "Cost after iteration 4200: 0.14256578791198787\n",
      "Cost after iteration 4300: 0.14565681792428092\n",
      "Cost after iteration 4400: 0.12171986726290908\n",
      "Cost after iteration 4499: 0.1370481311788364\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:53:08.750684Z",
     "start_time": "2025-06-08T12:53:08.712723Z"
    }
   },
   "cell_type": "code",
   "source": "plot_costs(costs_dropout, learning_rate)",
   "id": "f214f5bc8b52fde4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test",
   "id": "f0f703bd86e86840"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prediction (without dropout)",
   "id": "215745db1dc064e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:45:43.470650Z",
     "start_time": "2025-06-08T12:45:43.468036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "\n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "\n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "\n",
    "    probas, caches = forward_propagate(X, parameters)\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    accuracy = np.sum((p == y) / m)\n",
    "    return p, accuracy"
   ],
   "id": "b8c62dcbe48c36c5",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:45:44.928824Z",
     "start_time": "2025-06-08T12:45:44.925053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_, accuracy = predict(train_x, train_y, parameters)\n",
    "print(\"Accuracy (train):\", accuracy)\n",
    "_, accuracy = predict(test_x, test_y, parameters)\n",
    "print(\"Accuracy (test):\", accuracy)"
   ],
   "id": "4da2e9c768b9542c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 0.9904306220095691\n",
      "Accuracy (test): 0.7\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prediction (with dropout)",
   "id": "a25962460149e6bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:45:47.293207Z",
     "start_time": "2025-06-08T12:45:47.290959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_dropout(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "\n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "\n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    p = np.zeros((1,m))\n",
    "\n",
    "    probas, caches = forward_propagate_dropout(X, parameters)\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    accuracy = np.sum((p == y) / m)\n",
    "    return p, accuracy"
   ],
   "id": "1fcb122c98491911",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T12:53:11.609478Z",
     "start_time": "2025-06-08T12:53:11.605316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_, accuracy_dropout = predict_dropout(train_x, train_y, parameters_dropout)\n",
    "print(\"Accuracy (train):\", accuracy_dropout)\n",
    "_, accuracy_dropout = predict_dropout(test_x, test_y, parameters_dropout)\n",
    "print(\"Accuracy (test):\", accuracy_dropout)"
   ],
   "id": "857f963c1177a086",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 0.9617224880382773\n",
      "Accuracy (test): 0.74\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Gradient Checking\n",
    "\n",
    "Backpropagation computes the gradients $\\frac{\\partial J}{\\partial \\theta}$, where $\\theta$ denotes the parameters of the model. $J$ is computed using forward propagation and loss function.\n",
    "\n",
    "Definition of a derivative (or gradient):$$ \\frac{\\partial J}{\\partial \\theta} = \\lim_{\\varepsilon \\to 0} \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon}$$\n",
    "\n",
    "For each i in parameters:\n",
    "- Compute `J_p[i]`:\n",
    "    1. Set $\\theta^{+}$ to `np.copy(param_values)`\n",
    "    2. Set $\\theta^{+}_i$ to $\\theta^{+}_i + \\varepsilon$\n",
    "    3. Calculate $J^{+}_i$ using to `forward_propagate(X, vec_to_dic(`$\\theta^{+}$`, param_shapes))`.\n",
    "- To compute `J_m[i]`: do the same thing with $\\theta^{-}$\n",
    "- Compute $gradapprox[i] = \\frac{J^{+}_i - J^{-}_i}{2 \\varepsilon}$\n",
    "\n",
    "Where gradapprox[i] is an approximation of the gradient with respect to `param_values[i]`. Then comparing gradapprox vector with the gradients vector from backpropagation the difference can be received:\n",
    "$$ difference = \\frac {\\| grad - gradapprox \\|_2}{\\| grad \\|_2 + \\| gradapprox \\|_2 } \\tag{3}$$\n",
    "\n",
    "$10^{-7}$ or less is good, $10^{-5}$ need to double-check components, $10^{-3}$ - need to worry."
   ],
   "id": "17ec7d639912c1ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dic_to_vec(parameters):\n",
    "    theta = []\n",
    "    shapes = {}\n",
    "    count = 0\n",
    "    for key in [\"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\", \"W4\", \"b4\"]:\n",
    "        shapes[key] = parameters[key].shape\n",
    "        new_vector = np.reshape(parameters[key], (-1, 1))\n",
    "        if count == 0:\n",
    "            theta = new_vector\n",
    "        else:\n",
    "            theta = np.concatenate((theta, new_vector), axis=0)\n",
    "        count = count + 1\n",
    "    return theta, shapes"
   ],
   "id": "1d510081dcbae4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vec_to_dic(param_values, param_shapes):\n",
    "    parameters = {}\n",
    "    offset = 0\n",
    "    for key,shape in param_shapes.items():\n",
    "        items = shape[0] * shape[1]\n",
    "        parameters[key] = param_values[offset:offset+items].reshape(shape)\n",
    "        offset += items\n",
    "    return parameters"
   ],
   "id": "c0a9985375c85326",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grad_to_vec(gradients):\n",
    "    theta = []\n",
    "    count = 0\n",
    "    for key in [\"dW1\", \"db1\", \"dW2\", \"db2\", \"dW3\", \"db3\", \"dW4\", \"db4\"]:\n",
    "        new_vector = np.reshape(gradients[key], (-1, 1))\n",
    "        if count == 0:\n",
    "            theta = new_vector\n",
    "        else:\n",
    "            theta = np.concatenate((theta, new_vector), axis=0)\n",
    "        count += 1\n",
    "    return theta"
   ],
   "id": "27bf93c91c41ec5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def gradient_check(parameters, gradients, X, Y, N=100, epsilon=1e-7):\n",
    "    param_values, param_shapes = dic_to_vec(parameters)\n",
    "    grads = grad_to_vec(gradients)\n",
    "\n",
    "    No = param_values.shape[0]\n",
    "    J_p = np.zeros((No, 1))\n",
    "    J_m = np.zeros((No, 1))\n",
    "    gradapproxs = np.zeros((No, 1))\n",
    "\n",
    "    assert N <= No, \\\n",
    "        \"N parameter is invalid\"\n",
    "\n",
    "    for i in range(N):\n",
    "        theta_p = np.copy(param_values)\n",
    "        theta_p[i] = theta_p[i] + epsilon\n",
    "        Yp_hat, _ = forward_propagate(X, vec_to_dic(theta_p, param_shapes))\n",
    "        J_p[i] = compute_cost(Yp_hat, Y)\n",
    "\n",
    "        theta_m = np.copy(param_values)\n",
    "        theta_m[i] = theta_m[i] - epsilon\n",
    "        Ym_hat, _ = forward_propagate(X, vec_to_dic(theta_m, param_shapes))\n",
    "        J_m[i] = compute_cost(Ym_hat, Y)\n",
    "\n",
    "        gradapproxs[i] = (J_p[i] - J_m[i]) / (2 * epsilon)\n",
    "\n",
    "    num = np.linalg.norm(grads[:N] - gradapproxs[:N])\n",
    "    den = np.linalg.norm(grads[:N]) + np.linalg.norm(gradapproxs[:N])\n",
    "    differences = num / den\n",
    "    return differences\n"
   ],
   "id": "3258e01cfaf240e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parameters = initialize_parameters(layers_config)\n",
    "AL, caches = forward_propagate(train_x, parameters)\n",
    "gradients = backward_propagate(AL, train_y, caches)\n",
    "\n",
    "difference = gradient_check(parameters, gradients, train_x, train_y)\n",
    "print(\"Difference:\", difference)"
   ],
   "id": "ad3bb3ae1f82e8bf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
