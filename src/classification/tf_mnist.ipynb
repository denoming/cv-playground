{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TensorFlow: Classification using MNIST dataset\n",
    "\n",
    "Demonstrates creating DNN to accomplish image classification with Conv2D and MaxPool2D layers.\n",
    "Model is trained on fashion MNIST dataset."
   ],
   "id": "f0f79f5e378448c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:09:19.202872Z",
     "start_time": "2025-12-05T22:09:19.038181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "48230c61d7a697d0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T22:09:21.272202Z",
     "start_time": "2025-12-05T22:09:19.996731Z"
    }
   },
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF Eager mode: \", tf.executing_eagerly())\n",
    "print(\"TF GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.20.0\n",
      "TF Devices: ['CPU', 'GPU']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare Datasets",
   "id": "af46a2baf25bbf1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(train_ds, val_ds, test_ds), ds_info = tfds.load(\"fashion_mnist\",\n",
    "    split=[\"train[:80%]\", \"train[80%:]\", \"test\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True)"
   ],
   "id": "31157f9683d89136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_ = tfds.show_examples(train_ds.take(6), ds_info)",
   "id": "50dda89e12a2deed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_ds = (train_ds\n",
    "            .shuffle(buffer_size=1000)\n",
    "            .batch(32)\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "test_ds = (test_ds\n",
    "           .batch(32)\n",
    "           .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "val_ds = (val_ds\n",
    "          .batch(32)\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE))"
   ],
   "id": "7ec8027e51131080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T22:14:26.887074Z",
     "start_time": "2025-12-05T22:14:26.792756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds, info = tfds.load(\"mnist\", split=\"train\", with_info=True)\n",
    "tfds.as_dataframe(ds.take(3), info)"
   ],
   "id": "327e9ca6e2b110ea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 00:14:26.826783: W tensorflow/core/kernels/data/cache_dataset_ops.cc:917] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9befe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9befe_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_9befe_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9befe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9befe_row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_9befe_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9befe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9befe_row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_9befe_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9befe_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9befe_row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_9befe_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Model",
   "id": "5cf8cec142d48ace"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Rescaling(1.0 / 255.0),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    # tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ],
   "id": "132c6745e9382129",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot model architecture\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "id": "e17589fdc3b3d07b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    #loss=\"sparse_categorical_crossentropy\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"])"
   ],
   "id": "5fb4a6516d0a136c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5,\n",
    "        min_delta=1e-2,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=\"logs\",\n",
    "        histogram_freq=0,\n",
    "        embeddings_freq=0,\n",
    "        update_freq=\"epoch\"\n",
    "    )\n",
    "]\n",
    "\n",
    "%%time\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_ds,\n",
    "    verbose=2)"
   ],
   "id": "51a89a3357759a7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate Model",
   "id": "d91fbb7f0d829610"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.evaluate(test_ds)",
   "id": "c9c2789f901e6c84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]"
   ],
   "id": "1452ea430af24d1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xs = range(1, len(loss) + 1)\n",
    "plt.figure(figsize=(9,3))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(xs, loss, \"b\", label=\"Training Loss\")\n",
    "plt.plot(xs, val_loss, \"r\", label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(xs, accuracy, \"b\", label=\"Training Accuracy\")\n",
    "plt.plot(xs, val_accuracy, \"r\", label=\"Validation Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "3ee2fa092a515c63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict",
   "id": "1b05b42d49f5369a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create probability model from linear output of base model\n",
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ],
   "id": "d1b8a6f50d04fada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get experimental batch from test dataset\n",
    "images, true_labels = next(iter(test_ds.take(1)))"
   ],
   "id": "8f52529e95243617",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get predictions on the batch\n",
    "predictions = probability_model.predict(images)"
   ],
   "id": "c099bb725aeed61d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Collect predicted labels\n",
    "predicted_labels = np.array([np.argmax(prediction) for prediction in predictions])"
   ],
   "id": "f7a30bfbc89af67a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot true labels and predicted\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.grid(False)\n",
    "\n",
    "for i in range(32):\n",
    "    true_label = true_labels[i].numpy()\n",
    "    predicted_label = predicted_labels[i]\n",
    "    # Plot an image with label\n",
    "    plt.subplot(8, 8, (i*2) + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(images[i], cmap=\"binary\")\n",
    "    plt.xlabel(f\"{true_label} vs {predicted_label}\")\n",
    "    # Plot a bar with predictions\n",
    "    plt.subplot(8, 8, (i*2) + 2)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    plt.ylim([0, 1])\n",
    "    thisplot = plt.bar(range(10), predictions[i], color=\"r\")\n",
    "    thisplot[predicted_labels[i]].set_color(\"r\")\n",
    "    thisplot[true_labels[i]].set_color(\"b\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "7ac9a9451c55c42e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
