{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TensorFlow: DNN using transfer learning",
   "id": "d0180add0ef8c580"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "190f0fecd645e63c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF Eager mode: \", tf.executing_eagerly())\n",
    "print(\"TF GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
   ],
   "id": "30bdbe30e4192f3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from common import CV_DATA_DIR\n",
    "DATA_DIR = CV_DATA_DIR / \"animals\" / \"cats-and-dogs\"\n",
    "assert DATA_DIR.is_dir(),  \\\n",
    "    f\"Dir <{DATA_DIR}> does not exists\""
   ],
   "id": "105a48f3388614a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "cats_names = os.listdir(DATA_DIR / \"Cat\")\n",
    "dogs_names = os.listdir(DATA_DIR / \"Dog\")\n",
    "\n",
    "print(\"Total number of cat pictures: \", len(cats_names))\n",
    "print(\"Total number of dog pictures: \", len(dogs_names))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((ncols * 3, nrows * 3))\n",
    "\n",
    "next_cat_pix = [DATA_DIR / \"Cat\" / fname  for fname in random.sample(cats_names, k=8)]\n",
    "next_dog_pix = [DATA_DIR / \"Dog\" / fname  for fname in random.sample(dogs_names, k=8)]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix + next_dog_pix):\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis(\"off\")\n",
    "    image = mpimg.imread(img_path)\n",
    "    plt.imshow(image)"
   ],
   "id": "48c0332758c6c1c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare dataset",
   "id": "950383ab569b962c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T11:43:05.927368Z",
     "start_time": "2025-10-26T11:43:05.699605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    image_size=(150,150),\n",
    "    batch_size=64,\n",
    "    label_mode=\"binary\",\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    seed=1)"
   ],
   "id": "dfff3c5ac83461ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22434 files belonging to 2 classes.\n",
      "Using 20191 files for training.\n",
      "Using 2243 files for validation.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T11:43:06.933301Z",
     "start_time": "2025-10-26T11:43:06.926851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ds = (train_ds\n",
    "            .cache()\n",
    "            .shuffle(buffer_size=1000)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "val_ds = (val_ds\n",
    "          .cache()\n",
    "          .prefetch(tf.data.AUTOTUNE))"
   ],
   "id": "3013227bb07ab1ca",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pre-process input data using particular method\n",
    "# See https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input\n",
    "def preprocess(image, label):\n",
    "    image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)"
   ],
   "id": "e620232272b88d6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define model",
   "id": "d0fcd7d7a5ba477d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define base model\n",
    "\n",
    "* Get the architecture of existing model\n",
    "* Load weights to existing model\n",
    "* Freeze the weights of the layers\n",
    "* Select last layer to chain with"
   ],
   "id": "8e05ed5258792767"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Link to the file with weights of pre-trained model\n",
    "URL = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "weights_file = tf.keras.utils.get_file(\n",
    "    origin=URL\n",
    ")"
   ],
   "id": "616b4b9747697b50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Declare model without top (Dense) layer\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    input_shape=(150,150,3),\n",
    "    include_top=False,\n",
    "    weights=None\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "base_model.load_weights(weights_file)\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False"
   ],
   "id": "7f25d7535648feae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print model summary\n",
    "base_model.summary()"
   ],
   "id": "7be4a1ab431511ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Choose `mixed7` as the last layer of base model\n",
    "last_layer = base_model.get_layer(\"mixed7\")\n",
    "print(f\"Last layer output shape: {last_layer.output.shape}\")\n",
    "last_output = last_layer.output"
   ],
   "id": "b81df38617e895e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chain tuning layers\n",
    "\n",
    "* Add layers for tuning (training) to the top of the existing model"
   ],
   "id": "32a71f63c24dc733"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add layers to the pre-trained model (layers to learn weights)\n",
    "last_output = tf.keras.layers.Flatten()(last_output)\n",
    "last_output = tf.keras.layers.Dense(1024, activation=tf.nn.relu)(last_output)\n",
    "last_output = tf.keras.layers.Dropout(0.2)(last_output)\n",
    "last_output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(last_output)"
   ],
   "id": "dba803c19a34c5ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create final model without augmentation\n",
    "model_without_aug = tf.keras.Model(base_model.input, last_output)"
   ],
   "id": "962a9093c369fc7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print model summary\n",
    "model_without_aug.summary()"
   ],
   "id": "baa54f00252d5c77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chain augmentation layers",
   "id": "e1c28a614e531410"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aug_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.4),\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
    "    tf.keras.layers.RandomContrast(0.4),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "])"
   ],
   "id": "946c6955efc147c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inputs = tf.keras.Input(shape=(150,150,3))\n",
    "last_output = aug_layers(inputs)\n",
    "last_output = model_without_aug(last_output)\n",
    "\n",
    "model_with_aug = tf.keras.Model(inputs, last_output)"
   ],
   "id": "4d7391ec5d17c803",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_with_aug.compile(\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy'])"
   ],
   "id": "b5ce93d26473e177",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train model",
   "id": "137cd1df8cd2ab3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "%%time\n",
    "history = model_with_aug.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 2)"
   ],
   "id": "b4cfd1ace9659fc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate",
   "id": "1384ab658798e8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "ax[0].plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "ax[0].plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "ax[0].set_title(\"Training and validation accuracy\")\n",
    "ax[0].set_xlabel(\"epochs\")\n",
    "ax[0].set_ylabel(\"accuracy\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epochs, loss, \"bo\", label=\"Training Loss\")\n",
    "ax[1].plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "ax[1].set_title(\"Training and validation loss\")\n",
    "ax[1].set_xlabel(\"epochs\")\n",
    "ax[1].set_ylabel(\"loss\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "5e756d3ccb13ee26",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
