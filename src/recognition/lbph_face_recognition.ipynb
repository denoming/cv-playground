{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from common import CV_DATA_DIR\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "TRAIN_IMAGES = CV_DATA_DIR / 'yalefaces' / 'train'\n",
    "TESTS_IMAGES = CV_DATA_DIR / 'yalefaces' / 'test'\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('/usr/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "assert  not face_cascade.empty()\n",
    "\n",
    "def get_image_label(filename: str) -> int:\n",
    "    label = str()\n",
    "    for ch in filename:\n",
    "        if ch.isdigit():\n",
    "            label += ch\n",
    "    return int(label)\n",
    "\n",
    "def get_image_data(file: Path, padding: int = 5, scale_factor: float = 1.1, min_neighbors:int = 5) -> np.array:\n",
    "    image = np.array(Image.open(file).convert('L'), 'uint8')\n",
    "    faces = face_cascade.detectMultiScale(image, scale_factor, min_neighbors)\n",
    "    assert len(faces) == 1, \\\n",
    "        f\"Expected only one face at <{file}> image: {len(faces)} vs 1\"\n",
    "    cropped_image = None\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Crop image\n",
    "        cropped_image = image[y - padding + 1 : y + h + padding, x - padding + 1 : x + w + padding]\n",
    "        # Remove noise\n",
    "        cv2.GaussianBlur(cropped_image, [7, 7], 0, image)\n",
    "        # Equalize histogram\n",
    "        cv2.equalizeHist(cropped_image, cropped_image)\n",
    "    return cropped_image \n",
    "\n",
    "def get_images(path: Path) -> ([np.array], [int]):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(path):\n",
    "        file = Path(os.path.join(path, filename))\n",
    "        if file.is_file():\n",
    "            try:\n",
    "                images.append(get_image_data(file))\n",
    "                labels.append(get_image_label(filename))\n",
    "            except OSError as e:\n",
    "                print(f'Unable to read <{file}> file: {e.strerror}')\n",
    "    return images, np.array(labels)\n",
    "\n",
    "train_images, train_labels = get_images(TRAIN_IMAGES)\n",
    "assert len(train_labels) == len(train_images), \\\n",
    "    f\"The mount of labels and images must be equal: {len(train_labels)} vs {len(train_images)}\"\n",
    "tests_images, tests_labels = get_images(TESTS_IMAGES)\n",
    "assert len(tests_labels) == len(tests_images), \\\n",
    "    f\"The mount of labels and images must be equal: {len(tests_labels)} vs {len(tests_images)}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T10:43:05.846219Z",
     "start_time": "2024-05-02T10:43:03.870919Z"
    }
   },
   "id": "2d573199d38bb3ea",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T10:43:08.656898Z",
     "start_time": "2024-05-02T10:43:08.396651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and save classifier\n",
    "from common import CV_WORKAREA_DIR\n",
    "classifier1 = cv2.face.LBPHFaceRecognizer.create()\n",
    "classifier1.train(train_images, train_labels)\n",
    "classifier1.write(str(CV_WORKAREA_DIR / 'lbph_classifier.yml'))"
   ],
   "id": "9f5bfc1b446d46af",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load classifier and recognize faces\n",
    "classifier2 = cv2.face.LBPHFaceRecognizer.create()\n",
    "classifier2.read(str(CV_WORKAREA_DIR / 'lbph_classifier.yml'))\n",
    "\n",
    "\n",
    "predictions = []\n",
    "expected = []\n",
    "for image, label in zip(tests_images, tests_labels):\n",
    "    predict, confidence = classifier2.predict(image)\n",
    "    predictions.append(predict)\n",
    "    expected.append(label)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "expected = np.array(expected)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T10:43:10.984573Z",
     "start_time": "2024-05-02T10:43:10.199131Z"
    }
   },
   "id": "8fa4f02ebf3bb2da",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate recognizing result\n",
    "import seaborn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(expected, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.3}%')\n",
    "\n",
    "cm = confusion_matrix(expected, predictions)\n",
    "seaborn.heatmap(cm, annot=True);\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T10:43:12.783109Z",
     "start_time": "2024-05-02T10:43:12.482322Z"
    }
   },
   "id": "9a4a8a846527b6a6",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "47afe60a036d503d",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
